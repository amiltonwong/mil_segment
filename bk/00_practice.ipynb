{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 6 - Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hello, world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called 'hello_constant'\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# tf.constant() is called a constant tensor\n",
    "# A \"TensorFlow Session\", as shown above, is an environment for running a graph, \n",
    "# here, evaluate the tensor in a session.\n",
    "# The code creates a session instance, sess, using tf.Session. The sess.run() function then evaluates the tensor and returns the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Deferent size of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([123,456,789]) \n",
    " # C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input : using  tf.placeholder() and feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "tf.placeholder() returns a tensor that gets its value from data passed to the tf.session.run() function, allowing you to set the input right before the session runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello New World\n"
     ]
    }
   ],
   "source": [
    "# Sessionâ€™s feed_dict\n",
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello New World'})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n"
     ]
    }
   ],
   "source": [
    "# It's also possible to set more than one tensor using feed_dict as shown below\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Addition\n",
    "x = tf.add(5, 2)  # 7\n",
    "# Subtraction and Multiplication\n",
    "x = tf.subtract(10, 4) # 6\n",
    "y = tf.multiply(2, 5)  # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sub_2:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting types, tf.cast()\n",
    "tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# example quiz\n",
    "import tensorflow as tf\n",
    "\n",
    "# TODO: Convert the following to TensorFlow:\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.subtract(tf.div(x,y),tf.constant(1))\n",
    "\n",
    "# TODO: Print z from a session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary\n",
    "* Ran operations in tf.session.\n",
    "* Created a constant tensor with tf.constant().\n",
    "* Used tf.placeholder() and feed_dict to get input.\n",
    "* Applied the tf.add(), tf.subtract(), tf.multiply(), and tf.divide() functions using numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Supervised Classification - logistic classifier (aka. linear classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$WX+b=y$$ \n",
    "y(score) --> y(prob) by using softmax function. \n",
    "y(score) also called logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Weights and Bias in TensorFlow, using  tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable/read:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Variable Initialization\n",
    "x = tf.Variable(5)\n",
    "init = tf.global_variables_initializer()  #  initialize all TensorFlow variables from the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initializing the weights with random numbers from a normal distribution (is a good practice)\n",
    "# no need to randomize the bias\n",
    "# tf.truncated_normal()\n",
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "# no need to randomize the bias. Let's use the simplest solution, setting the bias to 0\n",
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Linear Classifier Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-19-dc6c17ef0341>:86: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 80, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 35, in linear\n    return tf.add(tf.matmul(input, w), b)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1827, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2392, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dc6c17ef0341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     _, l = session.run(\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         feed_dict={features: train_features, labels: train_labels})\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 80, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-19-dc6c17ef0341>\", line 35, in linear\n    return tf.add(tf.matmul(input, w), b)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1827, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2392, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(3118, 784), b.shape=(784, 3), m=3118, n=3, k=784\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_Placeholder_5_0/_7, Variable_3/read)]]\n"
     ]
    }
   ],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import tensorflow as tf\n",
    "\n",
    "def weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    # TODO: Return weights\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "def biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input, w), b)\n",
    "\n",
    "import tensorflow as tf\n",
    "# Sandbox Solution\n",
    "# Note: You can't run code in this tab\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#from quiz import weights, biases, linear\n",
    "\n",
    "\n",
    "def mnist_features_labels(n_labels):\n",
    "    \"\"\"\n",
    "    Gets the first <n> labels from the MNIST dataset\n",
    "    :param n_labels: Number of labels to use\n",
    "    :return: Tuple of feature list and label list\n",
    "    \"\"\"\n",
    "    mnist_features = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
    "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
    "\n",
    "        # Add features and labels if it's for the first <n>th labels\n",
    "        if mnist_label[:n_labels].any():\n",
    "            mnist_features.append(mnist_feature)\n",
    "            mnist_labels.append(mnist_label[:n_labels])\n",
    "\n",
    "    return mnist_features, mnist_labels\n",
    "\n",
    "\n",
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 3\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Weights and Biases\n",
    "w = weights(n_features, n_labels)\n",
    "b = biases(n_labels)\n",
    "\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)\n",
    "\n",
    "# Training data\n",
    "train_features, train_labels = mnist_features_labels(n_labels)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Cross entropy\n",
    "    # This quantifies how far off the predictions were.\n",
    "    # You'll learn more about this in future lessons.\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "    # Training loss\n",
    "    # You'll learn more about this in future lessons.\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Rate at which the weights are changed\n",
    "    # You'll learn more about this in future lessons.\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    # Gradient Descent\n",
    "    # This is the method used to train the model\n",
    "    # You'll learn more about this in future lessons.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Run optimizer and get loss\n",
    "    _, l = session.run(\n",
    "        [optimizer, loss],\n",
    "        feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# Print loss\n",
    "print('Loss: {}'.format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### softmax quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n",
      "[[ 0.09003057  0.00242826  0.01587624  0.33333333]\n",
      " [ 0.24472847  0.01794253  0.11731043  0.33333333]\n",
      " [ 0.66524096  0.97962921  0.86681333  0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# logits is a one-dimensional array\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))\n",
    "\n",
    "# logits is a two-dimensional array\n",
    "logits = np.array([\n",
    "    [1, 2, 3, 6],\n",
    "    [2, 4, 5, 6],\n",
    "    [3, 8, 7, 6]])\n",
    "\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Softmax quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09003057  0.00242826  0.01587624  0.33333334]\n",
      " [ 0.24472848  0.01794253  0.11731043  0.33333334]\n",
      " [ 0.66524094  0.97962922  0.86681336  0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# one-dimension\n",
    "#logit_data = [2.0, 1.0, 0.1]\n",
    "# logits is a two-dimensional array\n",
    "logit_data = np.array([\n",
    "    [1, 2, 3, 6],\n",
    "    [2, 4, 5, 6],\n",
    "    [3, 8, 7, 6]])\n",
    "\n",
    "logits = tf.placeholder(tf.float32)\n",
    "softmax = tf.nn.softmax(logits,dim=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-Hot Encoding : [1.0, 0, 0, 0 ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross Entropy: compare prediction vector (prob. vector: S(y)=softmax(y)) with one-hot encoding vector (L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### $$D(S,L) = -\\sum_{i} L_i log(S_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Multinomial logistic classification: $$D(S(WX+b), L)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Multinomial logistic classification quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# ToDo: Print cross entropy from session\n",
    "#  tf.reduce_sum() function takes an array of numbers and sums them together\n",
    "cross_entropy = -tf.reduce_sum(tf.mul(one_hot, tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cross_entropy, feed_dict={softmax: softmax_data, one_hot: one_hot_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loss (average cross entropy across data set)\n",
    "$$L = \\frac{1}{N}\\sum_{i}D(S(WX_i+b),L_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Normalized Inputs and Initial Weights (for numerial stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### zero mean: $$X_i = 0$$\n",
    "### equal variance: $$\\sigma (X_i) = \\sigma (X_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### input normalized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if dealing with images [0..255] \n",
    "# (R-128)/128, (G-128)/128, (B-128)/128\n",
    "# already , zero mean, unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### weight initialized as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# zero mean , equal variance, Guassian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization\n",
    "### $$W \\leftarrow W- \\alpha \\Delta_{W} L$$\n",
    "### $$b \\leftarrow b- \\alpha \\Delta_{b} L$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Momentum: change update from $$- \\alpha \\Delta L(w1,w2)$$ to $$- \\alpha M(w1,w2)$$\n",
    "where\n",
    "$$M \\leftarrow 0.9M + \\Delta L$$\n",
    "and M is the average of previous update direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Learning rate decay: $\\alpha$ becomes smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SGD 'hyerparameters'\n",
    "* initial learning rate\n",
    "* learning rate decay\n",
    "* momentum\n",
    "* batch size\n",
    "* weight initializatiogradn\n",
    "\n",
    "other approaches usch as Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mini-batching quiz (* if run out of GPU mememory, try to reduce value in min-batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Test Accuracy: 0.07589999586343765\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from helper import batches\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# TODO: Set batch size\n",
    "batch_size = 128\n",
    "assert batch_size is not None, 'You must set the batch size'\n",
    "\n",
    "#init = tf.initialize_all_variables()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TODO: Train optimizer on all batches\n",
    "    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Epochs\n",
    "An epoch is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 12.5     Valid Accuracy: 0.121\n",
      "Epoch: 1    - Cost: 11.4     Valid Accuracy: 0.139\n",
      "Epoch: 2    - Cost: 10.5     Valid Accuracy: 0.158\n",
      "Epoch: 3    - Cost: 9.79     Valid Accuracy: 0.177\n",
      "Epoch: 4    - Cost: 9.22     Valid Accuracy: 0.195\n",
      "Epoch: 5    - Cost: 8.73     Valid Accuracy: 0.211\n",
      "Epoch: 6    - Cost: 8.3      Valid Accuracy: 0.227\n",
      "Epoch: 7    - Cost: 7.9      Valid Accuracy: 0.241\n",
      "Epoch: 8    - Cost: 7.54     Valid Accuracy: 0.257\n",
      "Epoch: 9    - Cost: 7.21     Valid Accuracy: 0.272\n",
      "Test Accuracy: 0.2565999925136566\n"
     ]
    }
   ],
   "source": [
    "# example - 10 epochs\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from helper import batches  # Helper function created in Mini-batching section\n",
    "\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "tmp  = mnist.train.labels[0]\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 7 - Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ReLU (Rectified Linear Units)\n",
    "tf.nn.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hidden Layer with ReLU activation function\n",
    "hidden_layer = tf.add(tf.matmul(features, hidden_weights), hidden_biases)\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output = tf.add(tf.matmul(hidden_layer, output_weights), output_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow  ReLU Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-903963cf2b28>:34: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000023  38.24000168]]\n"
     ]
    }
   ],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import tensorflow as tf\n",
    "\n",
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "(?, 28, 28, 1)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Epoch: 0001 cost= 31.222970963\n",
      "Epoch: 0002 cost= 23.596107483\n",
      "Epoch: 0003 cost= 26.079868317\n",
      "Epoch: 0004 cost= 15.320896149\n",
      "Epoch: 0005 cost= 16.770378113\n",
      "Epoch: 0006 cost= 13.724834442\n",
      "Epoch: 0007 cost= 10.041910172\n",
      "Epoch: 0008 cost= 12.290496826\n",
      "Epoch: 0009 cost= 12.547527313\n",
      "Epoch: 0010 cost= 10.923553467\n",
      "Epoch: 0011 cost= 10.887722969\n",
      "Epoch: 0012 cost= 12.834579468\n",
      "Epoch: 0013 cost= 7.874982834\n",
      "Epoch: 0014 cost= 10.116508484\n",
      "Epoch: 0015 cost= 3.749085665\n",
      "Epoch: 0016 cost= 13.790746689\n",
      "Epoch: 0017 cost= 7.065402031\n",
      "Epoch: 0018 cost= 7.294026375\n",
      "Epoch: 0019 cost= 5.354338646\n",
      "Epoch: 0020 cost= 4.751398087\n",
      "Optimization Finished!\n",
      "Accuracy: 0.820312\n"
     ]
    }
   ],
   "source": [
    "# example: multilayer perceptron\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 128  # Decrease batch size if you don't have enough memory\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "n_hidden_layer = 256 # layer number of features\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # Decrease test_size if you don't have enough memory\n",
    "    test_size = 256\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:test_size], y: mnist.test.labels[:test_size]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save and Restore TensorFlow Models\n",
    "using  tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.22581583  0.97730374 -0.15746832]\n",
      " [-0.52505225 -1.2466743  -0.55889887]]\n",
      "Bias:\n",
      "[-0.70041877  0.16105421 -0.50394255]\n"
     ]
    }
   ],
   "source": [
    "# Saving Variables example\n",
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name=\"bias\")\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\n",
      "[[-0.22581583  0.97730374 -0.15746832]\n",
      " [-0.52505225 -1.2466743  -0.55889887]]\n",
      "Bias:\n",
      "[-0.70041877  0.16105421 -0.50394255]\n"
     ]
    }
   ],
   "source": [
    "# Loading Variables example\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name=\"bias\")\n",
    "\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]), name=\"weights\")\n",
    "bias = tf.Variable(tf.random_normal([n_classes]), name=\"bias\")\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Validation Accuracy: 0.11079999804496765\n",
      "Epoch 10  - Validation Accuracy: 0.26080000400543213\n",
      "Epoch 20  - Validation Accuracy: 0.4131999909877777\n",
      "Epoch 30  - Validation Accuracy: 0.5125999450683594\n",
      "Epoch 40  - Validation Accuracy: 0.5781998634338379\n",
      "Epoch 50  - Validation Accuracy: 0.6177998781204224\n",
      "Epoch 60  - Validation Accuracy: 0.6519998908042908\n",
      "Epoch 70  - Validation Accuracy: 0.681399941444397\n",
      "Epoch 80  - Validation Accuracy: 0.6997998952865601\n",
      "Epoch 90  - Validation Accuracy: 0.7171998620033264\n",
      "Trained Model Saved.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables to save",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0f53fb3209d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train_model.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m784\u001b[0m  \u001b[0;31m# MNIST data input (img shape: 28*28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/envs/python3.5_tf1.0a_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1070\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m       self.saver_def = self._builder.build(\n",
      "\u001b[0;31mValueError\u001b[0m: No variables to save"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_file = './train_model.ckpt'\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]), name=\"weights\")\n",
    "bias = tf.Variable(tf.random_normal([n_classes]), name=\"bias\")\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "\"\"\"\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\"\"\"\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.Variable'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3596cd4d35d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(type(weights))\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n",
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = './model_new3.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "save_file = './model_new3.ckpt'\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Regularization\n",
    "* early termination\n",
    "* L2 regularization: $L' = L + \\beta \\frac{1}{2}\\left \\| W \\right \\|_{2}^{2}$\n",
    "* Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Dropout Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8f016062c4ac>:34: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[  6.57999945   8.45999908]\n",
      " [  0.82600003   1.59000015]\n",
      " [  4.72000027  28.3200016 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print logits from a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(logits, feed_dict={keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 8 - Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### translation invariance - weight sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Map Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"SAME\" padding equation:\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"VALID\" padding equation:\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### conv layer dimension : calculate the number of neurons of output layer after conv\n",
    "\n",
    "Given:\n",
    "\n",
    "* our input layer has a width of W and a height of H\n",
    "* our convolutional layer has a filter size F\n",
    "* we have a stride of S\n",
    "* a padding of P\n",
    "* and the number of filters K,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "the following formula gives us the width of the next layer: W_out = (Wâˆ’F+2P)/S+1.\n",
    "\n",
    "The output height would be H_out = (H-F+2P)/S + 1.\n",
    "\n",
    "And the output depth would be equal to the number of filters D_out = K.\n",
    "\n",
    "The output volume would be W_out X H_out X D_out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convoultion output\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'SAME'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow \"same\" and \"valid\" padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SAME Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "\n",
    "out_width = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "# VALID Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides1))\n",
    "\n",
    "out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Convolution Layer\n",
    "using tf.nn.conv2d() and tf.nn.bias_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CNN in TensorFlow\n",
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Advanced Convnet-ology\n",
    "* pooling - decrease the size of the output and prevent overfitting\n",
    "    * max pooling\n",
    "    * average pooling\n",
    "* 1x1 convolution\n",
    "* inception model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TensorFlow Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-10c2f80c2844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Apply Max Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m conv_layer = tf.nn.max_pool(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight' is not defined"
     ]
    }
   ],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolutional Network in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "Epoch  1, Batch   1 - Loss: 50636.0469 Validation Accuracy: 0.097656\n",
      "Epoch  1, Batch   2 - Loss: 37016.1719 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   3 - Loss: 33846.1914 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   4 - Loss: 32600.9922 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch   5 - Loss: 34048.0195 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   6 - Loss: 27065.0391 Validation Accuracy: 0.132812\n",
      "Epoch  1, Batch   7 - Loss: 24950.3789 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch   8 - Loss: 22213.8086 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch   9 - Loss: 21871.4609 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  10 - Loss: 21934.1016 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch  11 - Loss: 18871.3848 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  12 - Loss: 19686.1680 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  13 - Loss: 17020.5352 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  14 - Loss: 17210.1738 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  15 - Loss: 15022.1807 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  16 - Loss: 18421.3008 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  17 - Loss: 15681.2227 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  18 - Loss: 17907.6953 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  19 - Loss: 17206.9746 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  20 - Loss: 18753.0527 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  21 - Loss: 16028.0254 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  22 - Loss: 17424.0703 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  23 - Loss: 14386.6846 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  24 - Loss: 13803.8730 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  25 - Loss: 11187.1416 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  26 - Loss: 12572.0547 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  27 - Loss: 12829.0088 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  28 - Loss: 14403.6211 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  29 - Loss: 15020.3262 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  30 - Loss: 11487.0693 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  31 - Loss: 14503.4326 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  32 - Loss: 12392.0635 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  33 - Loss: 12585.0381 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  34 - Loss: 10194.3281 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  35 - Loss: 10850.3652 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  36 - Loss: 10305.3105 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  37 - Loss: 10478.8037 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  38 - Loss: 10094.7500 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  39 - Loss:  8335.0234 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  40 - Loss: 10771.0967 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  41 - Loss:  9685.8848 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  42 - Loss:  8879.1113 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  43 - Loss: 10205.8359 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  44 - Loss: 11380.7461 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  45 - Loss:  9527.0195 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  46 - Loss:  9559.6816 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  47 - Loss:  9181.4189 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  48 - Loss:  7927.4878 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  49 - Loss:  8455.7637 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  50 - Loss:  8240.3320 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  51 - Loss:  8095.7109 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  52 - Loss:  9883.9902 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  53 - Loss:  9180.4912 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  54 - Loss:  6950.3267 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  55 - Loss:  8555.1504 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  56 - Loss:  9461.4141 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  57 - Loss: 10440.9668 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  58 - Loss:  8694.3506 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  59 - Loss:  9693.1914 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  60 - Loss:  7837.8154 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  61 - Loss:  7130.2568 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  62 - Loss:  7340.0542 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  63 - Loss:  7186.5376 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  64 - Loss:  8379.0586 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  65 - Loss:  7308.2070 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  66 - Loss:  7982.4341 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  67 - Loss:  6491.2075 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  68 - Loss:  4876.3047 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  69 - Loss:  8467.6738 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  70 - Loss:  7326.7378 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  71 - Loss:  7380.0293 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  72 - Loss:  7818.1870 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  73 - Loss:  8060.3154 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  74 - Loss:  5786.0801 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  75 - Loss:  8642.5488 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  76 - Loss:  9486.0000 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  77 - Loss:  7779.9668 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  78 - Loss:  5655.6123 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  79 - Loss:  4647.9932 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  80 - Loss:  6340.3896 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  81 - Loss:  5631.3223 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  82 - Loss:  6263.2725 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  83 - Loss:  4808.7827 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  84 - Loss:  6614.3940 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  85 - Loss:  7270.7891 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  86 - Loss:  6485.5928 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  87 - Loss:  6057.5820 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  88 - Loss:  5861.1045 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  89 - Loss:  5939.5874 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  90 - Loss:  5885.8794 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  91 - Loss:  4970.8867 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  92 - Loss:  6552.7393 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  93 - Loss:  5840.6328 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  94 - Loss:  6241.9014 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  95 - Loss:  5262.2021 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  96 - Loss:  5717.9048 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  97 - Loss:  5432.6260 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  98 - Loss:  5199.9785 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  99 - Loss:  5285.8174 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 100 - Loss:  5099.7925 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 101 - Loss:  6404.4609 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 102 - Loss:  4717.8398 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 103 - Loss:  3435.1072 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 104 - Loss:  5474.7891 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 105 - Loss:  6012.8115 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 106 - Loss:  5590.2422 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 107 - Loss:  5281.5938 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 108 - Loss:  4872.0356 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 109 - Loss:  4061.6704 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 110 - Loss:  4394.4678 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 111 - Loss:  4202.1211 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 112 - Loss:  4335.6768 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 113 - Loss:  4815.7822 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 114 - Loss:  4474.3271 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 115 - Loss:  3279.8259 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 116 - Loss:  3220.8716 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 117 - Loss:  4344.1538 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 118 - Loss:  5426.9980 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 119 - Loss:  4131.0195 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 120 - Loss:  3534.1187 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 121 - Loss:  3687.1597 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 122 - Loss:  3447.0903 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 123 - Loss:  4506.7769 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 124 - Loss:  4010.6511 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 125 - Loss:  5253.1699 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 126 - Loss:  3512.7642 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 127 - Loss:  3298.8586 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 128 - Loss:  4548.7881 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 129 - Loss:  5436.7769 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 130 - Loss:  3485.5225 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 131 - Loss:  3879.4192 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 132 - Loss:  2745.3877 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 133 - Loss:  3578.7632 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 134 - Loss:  4489.2852 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 135 - Loss:  4826.0464 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 136 - Loss:  4002.6086 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 137 - Loss:  4769.1777 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 138 - Loss:  4679.1367 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 139 - Loss:  3780.1550 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 140 - Loss:  3342.4009 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 141 - Loss:  3817.8638 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 142 - Loss:  4934.6182 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 143 - Loss:  4926.6045 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 144 - Loss:  3044.9636 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 145 - Loss:  3398.5742 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 146 - Loss:  4104.1899 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 147 - Loss:  3910.9221 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 148 - Loss:  3664.2241 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 149 - Loss:  4018.8394 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 150 - Loss:  3946.1641 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 151 - Loss:  3669.9009 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 152 - Loss:  2754.1543 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 153 - Loss:  3620.1309 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 154 - Loss:  3769.0347 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 155 - Loss:  5154.5532 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 156 - Loss:  3491.4351 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 157 - Loss:  3135.5911 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 158 - Loss:  3029.0874 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 159 - Loss:  3680.1001 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 160 - Loss:  2953.2056 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 161 - Loss:  3051.5947 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 162 - Loss:  2770.7156 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 163 - Loss:  2499.1890 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 164 - Loss:  2760.1687 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 165 - Loss:  3054.0781 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 166 - Loss:  3509.6318 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 167 - Loss:  3324.4482 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 168 - Loss:  4272.4961 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 169 - Loss:  4061.1765 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 170 - Loss:  4146.4785 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 171 - Loss:  3503.2354 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 172 - Loss:  2860.9863 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 173 - Loss:  4101.6279 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 174 - Loss:  3967.8491 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 175 - Loss:  2378.7285 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 176 - Loss:  2819.4668 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 177 - Loss:  2694.1672 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 178 - Loss:  3568.9136 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 179 - Loss:  3904.7124 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 180 - Loss:  2130.0332 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 181 - Loss:  2660.9524 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 182 - Loss:  3139.7080 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 183 - Loss:  2987.5396 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 184 - Loss:  2410.5620 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 185 - Loss:  2844.1387 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 186 - Loss:  3468.9321 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 187 - Loss:  2612.8674 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 188 - Loss:  2290.7007 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 189 - Loss:  2739.3062 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 190 - Loss:  2949.7166 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 191 - Loss:  2656.5840 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 192 - Loss:  2058.1719 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 193 - Loss:  2212.7808 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 194 - Loss:  3164.6401 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 195 - Loss:  3888.4536 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 196 - Loss:  3252.4561 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 197 - Loss:  3532.1802 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 198 - Loss:  2677.0750 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 199 - Loss:  3295.3308 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 200 - Loss:  3456.9797 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 201 - Loss:  3465.2510 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 202 - Loss:  3388.9814 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 203 - Loss:  3640.0713 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 204 - Loss:  4131.0234 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 205 - Loss:  2628.1821 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 206 - Loss:  4763.4443 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 207 - Loss:  3620.8496 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 208 - Loss:  2978.5171 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 209 - Loss:  4524.4814 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 210 - Loss:  2945.8511 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 211 - Loss:  2805.1851 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 212 - Loss:  3076.5938 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 213 - Loss:  2728.3760 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 214 - Loss:  3499.3811 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 215 - Loss:  3914.4504 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 216 - Loss:  1931.6208 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 217 - Loss:  2718.9395 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 218 - Loss:  2429.4431 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 219 - Loss:  3210.0811 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 220 - Loss:  1973.0577 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 221 - Loss:  2766.1301 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 222 - Loss:  2582.1333 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 223 - Loss:  3203.8386 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 224 - Loss:  2596.0928 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 225 - Loss:  3067.3765 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 226 - Loss:  1244.4357 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 227 - Loss:  1646.1211 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 228 - Loss:  1814.0671 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 229 - Loss:  1642.1396 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 230 - Loss:  3002.9353 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 231 - Loss:  2176.1450 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 232 - Loss:  2631.8413 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 233 - Loss:  2765.6777 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 234 - Loss:  2631.4734 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 235 - Loss:  2506.1729 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 236 - Loss:  2458.4302 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 237 - Loss:  2269.6697 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 238 - Loss:  2233.0728 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 239 - Loss:  2265.1724 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 240 - Loss:  1889.4042 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 241 - Loss:  2670.3745 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 242 - Loss:  2990.8567 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 243 - Loss:  2124.1279 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 244 - Loss:  1680.4219 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 245 - Loss:  2014.5342 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 246 - Loss:  1952.4893 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 247 - Loss:  2282.9956 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 248 - Loss:  2044.7102 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 249 - Loss:  2113.2488 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 250 - Loss:  1608.4514 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 251 - Loss:  2739.9170 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 252 - Loss:  1290.6552 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 253 - Loss:  2986.7393 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 254 - Loss:  2109.6248 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 255 - Loss:  2714.0881 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 256 - Loss:  1653.8092 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 257 - Loss:  2081.8064 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 258 - Loss:  1200.0680 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 259 - Loss:  2245.7444 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 260 - Loss:  3160.3091 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 261 - Loss:  1756.7483 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 262 - Loss:  1468.4446 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 263 - Loss:  2177.7341 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 264 - Loss:  1728.5283 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 265 - Loss:  1749.9475 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 266 - Loss:  1696.5280 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 267 - Loss:  1640.8088 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 268 - Loss:  2411.7324 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 269 - Loss:  2790.9783 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 270 - Loss:  1878.2100 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 271 - Loss:  2428.9189 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 272 - Loss:  2300.0227 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 273 - Loss:  2301.4961 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 274 - Loss:  2058.8506 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 275 - Loss:  2425.7708 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 276 - Loss:  2262.5142 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 277 - Loss:  1527.0085 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 278 - Loss:  1804.1619 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 279 - Loss:  2231.9614 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 280 - Loss:  1612.8912 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 281 - Loss:  1293.5400 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 282 - Loss:  2112.3503 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 283 - Loss:  1541.9595 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 284 - Loss:  2788.2600 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 285 - Loss:  2957.6787 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 286 - Loss:  2065.4849 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 287 - Loss:  2231.0598 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 288 - Loss:  2409.4302 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 289 - Loss:  1846.1140 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 290 - Loss:  1866.9213 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 291 - Loss:  2180.7734 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 292 - Loss:  2753.3843 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 293 - Loss:  2434.8054 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 294 - Loss:  1373.9973 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 295 - Loss:  2083.2017 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 296 - Loss:  2218.5037 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 297 - Loss:  2233.3257 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 298 - Loss:  2216.8086 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 299 - Loss:  1720.0764 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 300 - Loss:  1230.8251 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 301 - Loss:  1195.8317 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 302 - Loss:  1798.7471 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 303 - Loss:  1933.9219 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 304 - Loss:  2006.0863 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 305 - Loss:  2149.3086 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 306 - Loss:  1728.7607 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 307 - Loss:  2208.7112 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 308 - Loss:  2316.7642 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 309 - Loss:  1374.9911 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 310 - Loss:  1656.6986 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 311 - Loss:  1735.9736 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 312 - Loss:  1778.2557 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 313 - Loss:  2106.1560 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 314 - Loss:  1784.9305 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 315 - Loss:  1392.8931 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 316 - Loss:  2044.8665 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 317 - Loss:  2636.0366 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 318 - Loss:  1881.8055 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 319 - Loss:  2106.9250 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 320 - Loss:  1888.6270 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 321 - Loss:  2419.4958 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 322 - Loss:  1875.4679 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 323 - Loss:  1766.6008 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 324 - Loss:  2116.3955 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 325 - Loss:   924.4131 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 326 - Loss:  2340.5671 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 327 - Loss:  1914.8882 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 328 - Loss:  1637.6016 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 329 - Loss:  1070.7682 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 330 - Loss:  1812.0627 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 331 - Loss:  2050.3630 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 332 - Loss:  2403.8044 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 333 - Loss:  2513.9072 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 334 - Loss:  1723.4686 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 335 - Loss:  1070.7372 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 336 - Loss:  1919.6407 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 337 - Loss:  1320.9595 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 338 - Loss:   845.3456 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 339 - Loss:  2301.0369 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 340 - Loss:  1342.9204 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 341 - Loss:  1603.6896 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 342 - Loss:  1897.1956 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 343 - Loss:  1503.0054 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 344 - Loss:  3464.8411 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 345 - Loss:  2299.7046 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 346 - Loss:  2587.7512 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 347 - Loss:  1389.2126 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 348 - Loss:  2250.3113 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 349 - Loss:  2843.3877 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 350 - Loss:  1547.1367 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 351 - Loss:  1709.8143 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 352 - Loss:  1727.4385 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 353 - Loss:  1125.7275 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 354 - Loss:  2168.2661 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 355 - Loss:  2603.5908 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 356 - Loss:  1748.0156 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 357 - Loss:  1894.1255 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 358 - Loss:  2636.8232 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 359 - Loss:  2260.1294 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 360 - Loss:   711.5226 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 361 - Loss:  1463.6650 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 362 - Loss:  1938.3937 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 363 - Loss:  1499.0242 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 364 - Loss:  1131.1957 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 365 - Loss:  1281.4894 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 366 - Loss:  1467.3403 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 367 - Loss:  1206.4089 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 368 - Loss:  2237.9565 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 369 - Loss:  2213.0203 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 370 - Loss:  1792.6680 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 371 - Loss:  1108.9856 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 372 - Loss:   999.0851 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 373 - Loss:  1721.7861 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 374 - Loss:  1204.9413 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 375 - Loss:  2557.8420 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 376 - Loss:  1638.7202 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 377 - Loss:  1528.8979 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 378 - Loss:   915.9163 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 379 - Loss:  1552.3872 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 380 - Loss:  2017.8575 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 381 - Loss:   913.6428 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 382 - Loss:  1213.2821 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 383 - Loss:  1909.6189 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 384 - Loss:  1143.0707 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 385 - Loss:  1490.5559 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 386 - Loss:  1714.0664 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 387 - Loss:  1541.7434 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 388 - Loss:  1712.3123 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 389 - Loss:  1371.4236 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 390 - Loss:  1782.6957 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 391 - Loss:  1840.8273 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 392 - Loss:   960.8093 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 393 - Loss:  1286.1257 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 394 - Loss:  1482.8564 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 395 - Loss:  1843.0339 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 396 - Loss:  1250.4839 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 397 - Loss:  1477.7290 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 398 - Loss:  1386.2812 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 399 - Loss:   935.3036 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 400 - Loss:  1046.4835 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 401 - Loss:  1718.3164 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 402 - Loss:  1544.2272 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 403 - Loss:  1167.3125 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 404 - Loss:  1568.3303 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 405 - Loss:  1334.3699 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 406 - Loss:  1230.3068 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 407 - Loss:  1609.4741 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 408 - Loss:   903.3748 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 409 - Loss:  1885.3501 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 410 - Loss:  1440.5676 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 411 - Loss:  1361.6388 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 412 - Loss:  1986.1184 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 413 - Loss:   780.8158 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 414 - Loss:  1401.6350 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 415 - Loss:  1392.8884 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 416 - Loss:   478.7326 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 417 - Loss:   718.2513 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 418 - Loss:  1077.0171 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 419 - Loss:   934.5715 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 420 - Loss:   856.3800 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 421 - Loss:  1370.6447 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 422 - Loss:   395.8751 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 423 - Loss:   364.9006 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 424 - Loss:   721.6119 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 425 - Loss:  2548.8342 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 426 - Loss:  2024.3103 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 427 - Loss:   657.7797 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 428 - Loss:  1973.2621 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 429 - Loss:   680.9505 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   1 - Loss:  1481.4170 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   2 - Loss:  1388.6112 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch   3 - Loss:  1818.6019 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   4 - Loss:  1614.1748 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch   5 - Loss:  1417.8307 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch   6 - Loss:  1395.8428 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   7 - Loss:  1360.3467 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch   8 - Loss:  1351.1372 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch   9 - Loss:  2199.0557 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  10 - Loss:  1253.0161 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  11 - Loss:  1347.7942 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  12 - Loss:   882.8680 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  13 - Loss:  1465.9382 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  14 - Loss:  1632.8781 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  15 - Loss:  1602.9104 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  16 - Loss:  1390.3693 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  17 - Loss:  1211.4889 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  18 - Loss:  1407.9185 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  19 - Loss:  2266.9111 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  20 - Loss:  1153.4080 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  21 - Loss:  1383.3824 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  22 - Loss:  1018.8957 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  23 - Loss:  1318.7042 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  24 - Loss:  1787.8357 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  25 - Loss:  1378.6475 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  26 - Loss:  1054.4635 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  27 - Loss:  1799.3965 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  28 - Loss:  1035.1697 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  29 - Loss:   923.7595 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  30 - Loss:  1249.1725 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  31 - Loss:  1650.1523 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  32 - Loss:  1957.2065 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  33 - Loss:  1237.1427 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  34 - Loss:   855.0750 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  35 - Loss:  1665.5353 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  36 - Loss:  1500.5040 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  37 - Loss:  1099.5247 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  38 - Loss:   835.2358 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  39 - Loss:   879.2051 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  40 - Loss:  1033.9072 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  41 - Loss:  1967.5820 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  42 - Loss:  2241.3018 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  43 - Loss:  1446.5493 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  44 - Loss:  1444.0430 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  45 - Loss:  1457.6216 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  46 - Loss:  1785.9387 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  47 - Loss:  2371.1328 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  48 - Loss:  1590.4131 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  49 - Loss:   995.8771 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  50 - Loss:  1525.3300 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  51 - Loss:  1181.8547 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  52 - Loss:   886.5412 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  53 - Loss:  2141.7769 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  54 - Loss:  1026.7897 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  55 - Loss:  1243.6599 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  56 - Loss:  1023.7539 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  57 - Loss:  1162.0219 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  58 - Loss:  1215.4818 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  59 - Loss:  1256.6283 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  60 - Loss:  1032.6379 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  61 - Loss:  1210.0970 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  62 - Loss:  1239.9683 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  63 - Loss:   958.6838 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  64 - Loss:  1717.3518 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  65 - Loss:  1775.2013 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  66 - Loss:  1325.1921 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  67 - Loss:  1083.5593 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  68 - Loss:  1056.4218 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  69 - Loss:  1393.4424 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  70 - Loss:  1000.2740 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  71 - Loss:  1220.6349 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  72 - Loss:  1546.8098 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  73 - Loss:  1741.3442 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  74 - Loss:  1169.1658 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  75 - Loss:  1470.9371 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  76 - Loss:   850.5958 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  77 - Loss:   794.3218 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  78 - Loss:  1214.8489 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  79 - Loss:  1076.5500 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  80 - Loss:  1132.8073 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  81 - Loss:  1073.0397 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  82 - Loss:  1574.4943 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  83 - Loss:  1377.7710 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  84 - Loss:  1078.9506 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  85 - Loss:  1327.8032 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  86 - Loss:  1479.6206 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  87 - Loss:  1573.1490 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  88 - Loss:  1102.1128 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  89 - Loss:  1269.5189 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  90 - Loss:  1424.3159 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  91 - Loss:  1080.7679 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  92 - Loss:  1258.0790 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  93 - Loss:  1479.4194 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  94 - Loss:   713.7320 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  95 - Loss:  1230.9301 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  96 - Loss:  1277.4287 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  97 - Loss:   984.5456 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  98 - Loss:  1439.4492 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  99 - Loss:  1645.4359 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 100 - Loss:  1275.0446 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 101 - Loss:  1005.8603 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 102 - Loss:  1698.3169 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 103 - Loss:  1112.5421 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 104 - Loss:   975.8145 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 105 - Loss:  1281.8794 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 106 - Loss:  1382.2103 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 107 - Loss:  1468.2759 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 108 - Loss:   895.5193 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 109 - Loss:   694.3260 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 110 - Loss:   795.5569 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 111 - Loss:  1002.0701 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 112 - Loss:  1632.6176 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 113 - Loss:   900.1158 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 114 - Loss:  1161.9968 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 115 - Loss:  1385.3820 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 116 - Loss:  1022.4286 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 117 - Loss:  1353.3623 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 118 - Loss:  1258.4792 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 119 - Loss:  1386.9625 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 120 - Loss:  1096.5889 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 121 - Loss:  1198.1477 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 122 - Loss:  1176.1758 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 123 - Loss:   762.0161 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 124 - Loss:  1249.2666 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 125 - Loss:  1207.4856 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 126 - Loss:  1009.9631 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 127 - Loss:   730.4272 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 128 - Loss:   866.7844 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 129 - Loss:  1377.7073 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 130 - Loss:  1730.8276 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 131 - Loss:  1095.3005 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 132 - Loss:   678.2495 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 133 - Loss:   707.3280 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 134 - Loss:   753.1481 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 135 - Loss:   873.5288 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 136 - Loss:  1390.1692 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 137 - Loss:  1015.0731 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 138 - Loss:   971.9117 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 139 - Loss:  1479.5088 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 140 - Loss:  1137.6898 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 141 - Loss:   994.6476 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 142 - Loss:   710.3900 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 143 - Loss:   957.1260 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 144 - Loss:  1680.7330 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 145 - Loss:  1121.8873 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 146 - Loss:  1362.3376 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 147 - Loss:   953.1837 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 148 - Loss:  1091.8364 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 149 - Loss:  1100.0608 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 150 - Loss:  1099.3335 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 151 - Loss:  1641.8025 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 152 - Loss:   887.8640 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 153 - Loss:   697.0299 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 154 - Loss:  1217.6741 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 155 - Loss:  1289.9441 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 156 - Loss:  1313.2278 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 157 - Loss:   782.9609 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 158 - Loss:   869.2294 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 159 - Loss:  1312.0591 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 160 - Loss:  1003.2065 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 161 - Loss:  1205.0231 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 162 - Loss:  1508.2440 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 163 - Loss:  1683.6954 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 164 - Loss:  1380.5583 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 165 - Loss:  1242.5983 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 166 - Loss:  1501.7360 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 167 - Loss:  1065.8212 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 168 - Loss:  1526.4011 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 169 - Loss:   764.3287 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 170 - Loss:  1504.3104 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 171 - Loss:   956.3398 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 172 - Loss:  1008.8392 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 173 - Loss:  1322.5426 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 174 - Loss:   768.6942 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 175 - Loss:  1467.5652 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 176 - Loss:   884.7025 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 177 - Loss:  1057.4170 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 178 - Loss:  1310.5624 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 179 - Loss:  1186.5415 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 180 - Loss:  1169.6331 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 181 - Loss:   992.7518 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 182 - Loss:  1447.4414 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 183 - Loss:  1139.8265 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 184 - Loss:   853.0056 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 185 - Loss:  1587.2759 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 186 - Loss:   973.0990 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 187 - Loss:  1141.5149 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 188 - Loss:  1375.6543 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 189 - Loss:   691.3844 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 190 - Loss:   834.4749 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 191 - Loss:  1127.5879 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 192 - Loss:  1321.9504 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 193 - Loss:   889.2671 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 194 - Loss:  1345.5150 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 195 - Loss:  1028.3424 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 196 - Loss:  1099.3424 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 197 - Loss:   985.8727 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 198 - Loss:   988.4397 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 199 - Loss:  1165.5928 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 200 - Loss:  1264.9003 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 201 - Loss:  1573.1382 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 202 - Loss:  1185.0323 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 203 - Loss:  1708.4590 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 204 - Loss:   978.5307 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 205 - Loss:  1473.6711 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 206 - Loss:   443.9506 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 207 - Loss:  1122.1561 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 208 - Loss:   799.4172 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 209 - Loss:  1235.5173 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 210 - Loss:  1360.9937 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 211 - Loss:  1102.9990 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 212 - Loss:   978.1467 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 213 - Loss:  1009.4926 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 214 - Loss:  1162.7638 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 215 - Loss:  1388.1758 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 216 - Loss:   868.8821 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 217 - Loss:   997.9496 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 218 - Loss:  1114.0872 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 219 - Loss:   865.2473 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 220 - Loss:  1082.0920 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 221 - Loss:   593.9941 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 222 - Loss:   665.1269 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 223 - Loss:  1085.4313 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 224 - Loss:  1155.6827 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 225 - Loss:  1168.8888 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 226 - Loss:  1196.3467 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 227 - Loss:  1050.1537 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 228 - Loss:  1363.5786 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 229 - Loss:   644.2308 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 230 - Loss:   707.6566 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 231 - Loss:  1214.2291 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 232 - Loss:  1675.1350 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 233 - Loss:  1291.6288 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 234 - Loss:  1107.0063 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 235 - Loss:  1016.4202 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 236 - Loss:  1428.6466 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 237 - Loss:  1285.4595 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 238 - Loss:  1297.9445 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 239 - Loss:  1477.0367 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 240 - Loss:  1457.6433 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 241 - Loss:  1026.6185 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 242 - Loss:  1103.7688 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 243 - Loss:   888.6323 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 244 - Loss:  1283.2631 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 245 - Loss:  1283.7354 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 246 - Loss:  1229.7415 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 247 - Loss:  1198.2700 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 248 - Loss:   858.6414 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 249 - Loss:  1173.9485 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 250 - Loss:  1113.8063 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 251 - Loss:  1217.2725 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 252 - Loss:   877.2767 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 253 - Loss:  1173.6143 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 254 - Loss:   870.9277 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 255 - Loss:   954.8389 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 256 - Loss:  1219.5468 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 257 - Loss:   783.6957 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 258 - Loss:  1063.6908 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 259 - Loss:   706.3892 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 260 - Loss:   972.7158 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 261 - Loss:   900.6969 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 262 - Loss:  1584.0596 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 263 - Loss:   752.6302 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 264 - Loss:  1022.9587 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 265 - Loss:   826.5814 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 266 - Loss:  1429.3254 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 267 - Loss:  1024.1638 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 268 - Loss:   905.9414 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 269 - Loss:  1304.0419 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 270 - Loss:   774.4786 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 271 - Loss:   610.0689 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 272 - Loss:   606.2626 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 273 - Loss:  1212.0002 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 274 - Loss:   572.3167 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 275 - Loss:   903.6663 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 276 - Loss:   973.9266 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 277 - Loss:  1098.3254 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 278 - Loss:  1259.8777 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 279 - Loss:  1332.4977 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 280 - Loss:  1027.9458 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 281 - Loss:   918.9493 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 282 - Loss:   942.2845 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 283 - Loss:   736.8606 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 284 - Loss:  1060.4211 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 285 - Loss:   734.3120 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 286 - Loss:  1041.8348 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 287 - Loss:   976.5715 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 288 - Loss:  1039.0518 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 289 - Loss:  1284.5526 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 290 - Loss:  1139.6738 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 291 - Loss:   934.3367 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 292 - Loss:  1031.2059 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 293 - Loss:   787.7314 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 294 - Loss:   924.7880 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 295 - Loss:  1280.9484 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 296 - Loss:   915.3211 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 297 - Loss:   501.3708 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 298 - Loss:   833.8276 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 299 - Loss:  1117.5123 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 300 - Loss:  1065.6858 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 301 - Loss:   912.0331 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 302 - Loss:  1049.5077 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 303 - Loss:   891.0254 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 304 - Loss:  1264.7981 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 305 - Loss:   680.3175 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 306 - Loss:  1009.3737 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 307 - Loss:   756.4945 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 308 - Loss:  1068.9125 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 309 - Loss:  1107.2208 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 310 - Loss:   662.4178 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 311 - Loss:   925.3650 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 312 - Loss:   986.7503 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 313 - Loss:   688.4867 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 314 - Loss:   783.8665 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 315 - Loss:   828.4948 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 316 - Loss:   958.7335 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 317 - Loss:   744.1165 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 318 - Loss:  1049.9072 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 319 - Loss:   641.7163 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 320 - Loss:   970.9487 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 321 - Loss:   947.6110 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 322 - Loss:   991.0225 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 323 - Loss:   903.8439 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 324 - Loss:   841.6237 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 325 - Loss:  1558.8552 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 326 - Loss:  1207.2118 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 327 - Loss:   738.2051 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 328 - Loss:   596.8898 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 329 - Loss:   729.1028 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 330 - Loss:   703.6387 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 331 - Loss:   950.6047 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 332 - Loss:   800.9397 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 333 - Loss:   944.7316 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 334 - Loss:   780.5555 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 335 - Loss:  1246.1526 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 336 - Loss:   855.5186 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 337 - Loss:   839.2252 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 338 - Loss:   836.0472 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 339 - Loss:  1299.2267 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 340 - Loss:  1172.1587 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 341 - Loss:   868.8787 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 342 - Loss:   849.9405 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 343 - Loss:   847.4753 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 344 - Loss:  1025.3638 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 345 - Loss:   767.1099 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 346 - Loss:   495.7625 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 347 - Loss:   801.7836 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 348 - Loss:   961.9043 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 349 - Loss:   853.6710 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 350 - Loss:   910.0388 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 351 - Loss:   587.1880 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 352 - Loss:  1226.6482 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 353 - Loss:   822.1417 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 354 - Loss:  1145.3380 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 355 - Loss:   865.0458 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 356 - Loss:  1044.2040 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 357 - Loss:   601.6558 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 358 - Loss:   966.5309 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 359 - Loss:   760.6519 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 360 - Loss:   949.7186 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 361 - Loss:  1128.5507 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 362 - Loss:  1056.7600 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 363 - Loss:   873.3372 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 364 - Loss:   876.1290 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 365 - Loss:  1217.2000 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 366 - Loss:   834.1902 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 367 - Loss:  1425.9712 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 368 - Loss:   984.1445 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 369 - Loss:   829.4576 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 370 - Loss:  1181.3043 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 371 - Loss:  1180.8591 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 372 - Loss:   928.5785 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 373 - Loss:  1041.4716 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 374 - Loss:   917.0157 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 375 - Loss:   959.1187 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 376 - Loss:   771.4533 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 377 - Loss:   825.0502 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 378 - Loss:   930.8549 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 379 - Loss:   873.8273 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 380 - Loss:  1134.1746 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 381 - Loss:   727.2869 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 382 - Loss:   815.3826 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 383 - Loss:  1156.6257 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 384 - Loss:   707.3427 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 385 - Loss:   839.0400 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 386 - Loss:   833.8617 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 387 - Loss:   828.8936 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 388 - Loss:   685.0130 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 389 - Loss:   692.6486 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 390 - Loss:   455.1357 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 391 - Loss:   903.9399 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 392 - Loss:   877.6492 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 393 - Loss:   702.5171 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 394 - Loss:  1056.8210 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 395 - Loss:  1055.7316 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 396 - Loss:   851.9379 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 397 - Loss:  1010.2373 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 398 - Loss:  1276.6783 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 399 - Loss:   739.8953 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 400 - Loss:  1030.4165 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 401 - Loss:  1288.9991 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 402 - Loss:   713.6526 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 403 - Loss:   728.6293 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 404 - Loss:   844.8909 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 405 - Loss:   940.5611 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 406 - Loss:   754.9830 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 407 - Loss:  1156.7046 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 408 - Loss:   881.9303 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 409 - Loss:   690.7548 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 410 - Loss:   927.1805 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 411 - Loss:   772.1284 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 412 - Loss:   873.6674 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 413 - Loss:   632.2151 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 414 - Loss:   764.0684 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 415 - Loss:   395.8645 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 416 - Loss:   612.9469 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 417 - Loss:   822.4950 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 418 - Loss:   694.2957 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 419 - Loss:  1336.5753 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 420 - Loss:   756.5190 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 421 - Loss:  1288.8850 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 422 - Loss:   861.5040 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 423 - Loss:   728.6704 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 424 - Loss:   632.3210 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 425 - Loss:   625.3807 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 426 - Loss:   364.3039 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 427 - Loss:   906.0116 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 428 - Loss:   570.8752 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 429 - Loss:   810.5224 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   1 - Loss:   582.3799 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   2 - Loss:  1213.9872 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   3 - Loss:  1039.4016 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   4 - Loss:   877.1439 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   5 - Loss:   743.1718 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch   6 - Loss:   702.8563 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch   7 - Loss:  1030.1366 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   8 - Loss:   514.7905 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch   9 - Loss:   766.5476 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  10 - Loss:  1004.3032 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  11 - Loss:   617.1831 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  12 - Loss:   595.0464 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  13 - Loss:  1065.0544 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  14 - Loss:  1180.7181 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  15 - Loss:  1024.1152 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  16 - Loss:   714.4519 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  17 - Loss:   652.2241 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  18 - Loss:   988.2792 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  19 - Loss:  1090.2739 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  20 - Loss:  1295.9161 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  21 - Loss:  1095.7465 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  22 - Loss:   996.9790 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  23 - Loss:   813.5395 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  24 - Loss:   972.6348 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  25 - Loss:   768.0087 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  26 - Loss:   660.4169 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  27 - Loss:   919.8279 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  28 - Loss:  1031.1478 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  29 - Loss:   819.9004 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  30 - Loss:   904.7576 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  31 - Loss:   661.4388 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  32 - Loss:   602.1022 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  33 - Loss:   880.2520 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  34 - Loss:   639.1672 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  35 - Loss:   660.4298 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  36 - Loss:   823.6992 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  37 - Loss:  1120.7859 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  38 - Loss:   803.8318 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  39 - Loss:   477.2360 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  40 - Loss:   860.1199 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  41 - Loss:   561.9608 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  42 - Loss:   721.3253 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  43 - Loss:   667.2630 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  44 - Loss:   852.0320 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  45 - Loss:   807.9187 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  46 - Loss:   848.8004 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  47 - Loss:   351.2500 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  48 - Loss:   759.2275 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  49 - Loss:  1025.3049 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  50 - Loss:   765.1791 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  51 - Loss:   757.0739 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  52 - Loss:  1133.6705 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  53 - Loss:   669.0810 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch  54 - Loss:   866.9846 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  55 - Loss:   592.4161 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  56 - Loss:   813.0759 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  57 - Loss:   925.8465 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  58 - Loss:   515.3752 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  59 - Loss:   588.8007 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  60 - Loss:   708.7122 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  61 - Loss:   555.1881 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  62 - Loss:   921.4337 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  63 - Loss:   496.4324 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  64 - Loss:   923.4818 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  65 - Loss:   435.4260 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  66 - Loss:   629.4202 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  67 - Loss:   768.5373 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  68 - Loss:  1175.2222 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  69 - Loss:   987.0123 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  70 - Loss:   769.0117 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  71 - Loss:   720.9084 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  72 - Loss:   756.9911 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch  73 - Loss:  1273.9302 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  74 - Loss:   842.3932 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  75 - Loss:   932.3173 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch  76 - Loss:   788.1821 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  77 - Loss:  1044.1375 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  78 - Loss:   574.6639 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  79 - Loss:  1111.9957 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  80 - Loss:   961.7523 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  81 - Loss:   968.2778 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  82 - Loss:   712.8620 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  83 - Loss:  1041.0496 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  84 - Loss:   661.5169 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  85 - Loss:   642.6317 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  86 - Loss:   674.4010 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  87 - Loss:   729.7843 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  88 - Loss:   720.5673 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  89 - Loss:   559.3409 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  90 - Loss:   648.4757 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  91 - Loss:  1131.2609 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  92 - Loss:   805.4467 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  93 - Loss:   793.5677 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  94 - Loss:   606.5776 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  95 - Loss:   891.4484 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  96 - Loss:   759.8275 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch  97 - Loss:   862.0862 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch  98 - Loss:   699.7812 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch  99 - Loss:  1052.7732 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 100 - Loss:  1274.9874 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 101 - Loss:   871.8252 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 102 - Loss:   734.7357 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 103 - Loss:   913.6565 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 104 - Loss:   863.6614 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 105 - Loss:   479.4995 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 106 - Loss:   970.0210 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 107 - Loss:   952.3370 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 108 - Loss:   652.2529 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 109 - Loss:   775.8853 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 110 - Loss:   889.9668 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 111 - Loss:  1026.9049 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 112 - Loss:   835.9940 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 113 - Loss:   591.2511 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 114 - Loss:   675.2285 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 115 - Loss:   565.6364 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 116 - Loss:   828.2687 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 117 - Loss:   748.1538 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 118 - Loss:   707.5128 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 119 - Loss:   691.1436 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 120 - Loss:   623.0228 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 121 - Loss:   461.3871 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 122 - Loss:   796.2656 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 123 - Loss:   536.1580 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 124 - Loss:   757.6355 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 125 - Loss:   878.2696 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 126 - Loss:   819.6884 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 127 - Loss:   655.8213 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 128 - Loss:   643.4260 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 129 - Loss:   751.1794 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch 130 - Loss:   917.7056 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 131 - Loss:  1009.5446 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 132 - Loss:   725.3045 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 133 - Loss:   888.5967 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 134 - Loss:  1006.7119 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 135 - Loss:   735.5664 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 136 - Loss:   709.9183 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 137 - Loss:   947.9603 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 138 - Loss:   556.2149 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 139 - Loss:   843.1756 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 140 - Loss:   558.9099 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 141 - Loss:   737.2210 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 142 - Loss:   398.5495 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 143 - Loss:   809.0193 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 144 - Loss:   856.9822 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 145 - Loss:   839.3052 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 146 - Loss:   673.1511 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 147 - Loss:   865.1240 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 148 - Loss:   760.2570 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 149 - Loss:   670.1753 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 150 - Loss:   927.3595 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 151 - Loss:   379.4918 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 152 - Loss:   794.4022 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 153 - Loss:   836.8723 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 154 - Loss:   624.1117 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 155 - Loss:   895.9547 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 156 - Loss:   890.9879 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 157 - Loss:   572.4795 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 158 - Loss:   684.1894 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 159 - Loss:   613.5149 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 160 - Loss:   720.4446 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 161 - Loss:   586.8740 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 162 - Loss:   754.1459 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 163 - Loss:   723.4176 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 164 - Loss:   557.4335 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 165 - Loss:   827.3405 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 166 - Loss:  1101.6991 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 167 - Loss:   736.7239 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 168 - Loss:   766.7007 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 169 - Loss:   731.6932 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 170 - Loss:   918.3998 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 171 - Loss:  1008.1339 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 172 - Loss:   909.7593 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 173 - Loss:   703.8937 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 174 - Loss:   852.2908 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 175 - Loss:   534.6571 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 176 - Loss:   776.6738 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 177 - Loss:   479.4145 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 178 - Loss:   731.9458 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 179 - Loss:   572.7134 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 180 - Loss:   602.5806 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 181 - Loss:   925.6206 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 182 - Loss:   633.8637 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 183 - Loss:   409.6327 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 184 - Loss:   896.3909 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch 185 - Loss:   970.3029 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 186 - Loss:   825.1793 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 187 - Loss:   465.7772 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 188 - Loss:   746.8040 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 189 - Loss:   716.5175 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 190 - Loss:   927.6948 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 191 - Loss:   811.7146 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 192 - Loss:   964.1470 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 193 - Loss:   945.8350 Validation Accuracy: 0.769531\n",
      "Epoch  3, Batch 194 - Loss:   618.8157 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 195 - Loss:   558.8477 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 196 - Loss:   809.3194 Validation Accuracy: 0.765625\n",
      "Epoch  3, Batch 197 - Loss:   477.3643 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 198 - Loss:   674.9237 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 199 - Loss:   746.6035 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 200 - Loss:   810.7092 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 201 - Loss:  1148.0356 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 202 - Loss:   747.9638 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 203 - Loss:   595.6196 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 204 - Loss:   770.0432 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 205 - Loss:   771.1245 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 206 - Loss:   557.9005 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 207 - Loss:   673.3239 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 208 - Loss:   574.0038 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 209 - Loss:  1010.0469 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 210 - Loss:   768.6826 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 211 - Loss:   608.8014 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 212 - Loss:   895.2977 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 213 - Loss:   639.2757 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 214 - Loss:   612.1055 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 215 - Loss:   580.3796 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 216 - Loss:   425.1665 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 217 - Loss:   941.0141 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 218 - Loss:   867.2290 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 219 - Loss:   349.9778 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 220 - Loss:   609.0736 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 221 - Loss:   528.4698 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 222 - Loss:   747.4460 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 223 - Loss:   746.3887 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 224 - Loss:   825.4346 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 225 - Loss:   382.4065 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 226 - Loss:   952.0948 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 227 - Loss:   534.4003 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 228 - Loss:   747.5373 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 229 - Loss:   878.8591 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 230 - Loss:   643.7148 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 231 - Loss:   706.8120 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 232 - Loss:   808.1570 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 233 - Loss:   462.5255 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 234 - Loss:   698.3221 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 235 - Loss:   543.8641 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 236 - Loss:   957.7125 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 237 - Loss:   517.0400 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 238 - Loss:  1016.8164 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 239 - Loss:   793.2986 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 240 - Loss:   659.3331 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 241 - Loss:   918.9510 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 242 - Loss:   579.3527 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 243 - Loss:   804.0123 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 244 - Loss:   772.7247 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 245 - Loss:  1159.6783 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 246 - Loss:   884.3866 Validation Accuracy: 0.773438\n",
      "Epoch  3, Batch 247 - Loss:   769.5164 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 248 - Loss:   500.1660 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 249 - Loss:   453.1276 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 250 - Loss:   911.0919 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 251 - Loss:   811.6772 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 252 - Loss:   570.8141 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 253 - Loss:   918.1228 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 254 - Loss:   574.0645 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 255 - Loss:   651.2224 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 256 - Loss:   633.7943 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 257 - Loss:   561.6617 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 258 - Loss:   926.3577 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 259 - Loss:   621.7775 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 260 - Loss:   356.0169 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 261 - Loss:   569.3766 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 262 - Loss:   576.9980 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 263 - Loss:  1021.3115 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 264 - Loss:   898.0146 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 265 - Loss:   799.3892 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 266 - Loss:   927.4807 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 267 - Loss:   672.0709 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 268 - Loss:   842.5936 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 269 - Loss:   397.5851 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 270 - Loss:   940.4562 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 271 - Loss:   472.6609 Validation Accuracy: 0.777344\n",
      "Epoch  3, Batch 272 - Loss:   771.9421 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 273 - Loss:   718.0700 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 274 - Loss:   763.9873 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 275 - Loss:   910.0526 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 276 - Loss:   711.5229 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 277 - Loss:   899.7980 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 278 - Loss:   708.2832 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 279 - Loss:   827.8489 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 280 - Loss:  1092.5267 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 281 - Loss:   701.7341 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 282 - Loss:  1045.7618 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 283 - Loss:   749.7810 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 284 - Loss:   922.8898 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 285 - Loss:   326.7271 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 286 - Loss:   581.6327 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 287 - Loss:   777.2816 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 288 - Loss:   502.5968 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 289 - Loss:   938.8586 Validation Accuracy: 0.781250\n",
      "Epoch  3, Batch 290 - Loss:   544.0980 Validation Accuracy: 0.785156\n",
      "Epoch  3, Batch 291 - Loss:   498.6769 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 292 - Loss:   842.4394 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 293 - Loss:   572.5706 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 294 - Loss:   599.5074 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 295 - Loss:   641.7992 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 296 - Loss:   660.3042 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 297 - Loss:   602.5374 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 298 - Loss:   511.0273 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 299 - Loss:   716.8639 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 300 - Loss:   559.1533 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 301 - Loss:   697.6469 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 302 - Loss:   496.8276 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 303 - Loss:   591.2059 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 304 - Loss:   411.6675 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 305 - Loss:   651.4082 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 306 - Loss:   788.1402 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 307 - Loss:   839.2995 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 308 - Loss:   749.4680 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 309 - Loss:   763.8176 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 310 - Loss:   837.1730 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 311 - Loss:   579.5295 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 312 - Loss:   680.5295 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 313 - Loss:   804.2161 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 314 - Loss:   574.2592 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 315 - Loss:   844.7889 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 316 - Loss:   668.7284 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 317 - Loss:   638.7412 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 318 - Loss:   640.8724 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 319 - Loss:   415.2780 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 320 - Loss:   807.9830 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 321 - Loss:   957.6924 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 322 - Loss:   737.0985 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 323 - Loss:   739.5590 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 324 - Loss:   569.5649 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 325 - Loss:   942.9823 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 326 - Loss:   566.1447 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 327 - Loss:   539.4880 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 328 - Loss:   692.8191 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 329 - Loss:   841.0278 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 330 - Loss:   500.2542 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 331 - Loss:   306.0421 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 332 - Loss:   567.5117 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 333 - Loss:   607.6985 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 334 - Loss:   750.0699 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 335 - Loss:   417.7313 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 336 - Loss:   944.9650 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 337 - Loss:   716.4169 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 338 - Loss:   377.3896 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 339 - Loss:   278.9467 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 340 - Loss:   587.7610 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 341 - Loss:   673.9112 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 342 - Loss:   502.0122 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 343 - Loss:   653.4277 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 344 - Loss:   645.2968 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 345 - Loss:   825.7853 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 346 - Loss:   423.4078 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 347 - Loss:   674.9327 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 348 - Loss:   598.4992 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 349 - Loss:   988.0592 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 350 - Loss:   687.0159 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 351 - Loss:   565.3563 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 352 - Loss:   498.8437 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 353 - Loss:   595.8255 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 354 - Loss:   551.1694 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 355 - Loss:   585.4831 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 356 - Loss:   396.1602 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 357 - Loss:   709.2629 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 358 - Loss:   598.6912 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 359 - Loss:   796.6412 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 360 - Loss:   626.7435 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 361 - Loss:   517.8762 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 362 - Loss:   611.6989 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 363 - Loss:   736.7363 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 364 - Loss:   623.1552 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 365 - Loss:   691.1396 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 366 - Loss:   746.8539 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 367 - Loss:   664.1224 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 368 - Loss:   546.6572 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 369 - Loss:   806.9622 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 370 - Loss:   687.4875 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 371 - Loss:   469.1732 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 372 - Loss:   605.3164 Validation Accuracy: 0.789062\n",
      "Epoch  3, Batch 373 - Loss:   825.5052 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 374 - Loss:   506.1804 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 375 - Loss:   743.4683 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 376 - Loss:   831.4705 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 377 - Loss:   786.7760 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 378 - Loss:   828.8596 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 379 - Loss:   670.4832 Validation Accuracy: 0.792969\n",
      "Epoch  3, Batch 380 - Loss:   710.4764 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 381 - Loss:   816.1891 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 382 - Loss:  1034.5038 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 383 - Loss:   694.6962 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 384 - Loss:   702.8228 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 385 - Loss:   660.6330 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 386 - Loss:   653.3713 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 387 - Loss:   907.6414 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 388 - Loss:   795.9872 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 389 - Loss:   764.7121 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 390 - Loss:   532.9883 Validation Accuracy: 0.796875\n",
      "Epoch  3, Batch 391 - Loss:   280.3254 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 392 - Loss:   456.8960 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 393 - Loss:   620.1628 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 394 - Loss:   661.3385 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 395 - Loss:   541.5039 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 396 - Loss:   688.7424 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 397 - Loss:   473.8757 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 398 - Loss:   445.4108 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 399 - Loss:   689.8132 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 400 - Loss:   801.4885 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 401 - Loss:   565.6225 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 402 - Loss:   386.3115 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 403 - Loss:   484.1065 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 404 - Loss:   542.6957 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 405 - Loss:   732.8892 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 406 - Loss:   518.0381 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 407 - Loss:   565.9214 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 408 - Loss:   249.5845 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 409 - Loss:   708.4460 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 410 - Loss:   707.8617 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 411 - Loss:   671.0895 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 412 - Loss:   704.8431 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 413 - Loss:   488.9496 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 414 - Loss:   583.0090 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 415 - Loss:   511.2446 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 416 - Loss:   735.1376 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 417 - Loss:   771.5621 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 418 - Loss:   623.4515 Validation Accuracy: 0.800781\n",
      "Epoch  3, Batch 419 - Loss:   438.7188 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 420 - Loss:   485.4966 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 421 - Loss:   579.3618 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 422 - Loss:   414.3284 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 423 - Loss:   494.5348 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 424 - Loss:   806.3684 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 425 - Loss:   702.5012 Validation Accuracy: 0.808594\n",
      "Epoch  3, Batch 426 - Loss:   642.9614 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 427 - Loss:   530.3625 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 428 - Loss:   647.7554 Validation Accuracy: 0.804688\n",
      "Epoch  3, Batch 429 - Loss:   394.6172 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch   1 - Loss:   603.2416 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch   2 - Loss:   593.1198 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch   3 - Loss:   675.6188 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch   4 - Loss:   608.6644 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch   5 - Loss:   792.3705 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch   6 - Loss:   725.7299 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch   7 - Loss:   762.3700 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch   8 - Loss:   543.9716 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch   9 - Loss:   648.4363 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  10 - Loss:   574.6334 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  11 - Loss:   484.6943 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  12 - Loss:   576.5923 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  13 - Loss:   644.5050 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  14 - Loss:   446.8557 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  15 - Loss:   883.9076 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  16 - Loss:   565.9873 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  17 - Loss:   530.9723 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  18 - Loss:   698.3635 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  19 - Loss:   482.7825 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  20 - Loss:   603.8730 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  21 - Loss:   510.9980 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  22 - Loss:   493.1228 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  23 - Loss:   403.7272 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  24 - Loss:   671.3840 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  25 - Loss:   557.3871 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  26 - Loss:   633.9746 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch  27 - Loss:   605.7170 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  28 - Loss:   683.1292 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  29 - Loss:   638.0010 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  30 - Loss:   508.7080 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  31 - Loss:   628.9974 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  32 - Loss:   711.2815 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  33 - Loss:   610.7858 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  34 - Loss:   699.9437 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  35 - Loss:   537.8727 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  36 - Loss:   543.1080 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  37 - Loss:   684.0447 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  38 - Loss:   657.2443 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  39 - Loss:   551.7039 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  40 - Loss:   562.5046 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch  41 - Loss:   626.4498 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch  42 - Loss:   662.1626 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  43 - Loss:   743.9002 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  44 - Loss:   812.0332 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  45 - Loss:   834.7249 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  46 - Loss:   487.5659 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  47 - Loss:   645.2101 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  48 - Loss:   484.4633 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  49 - Loss:   575.3458 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  50 - Loss:   535.2609 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  51 - Loss:   651.8760 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  52 - Loss:   564.0521 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  53 - Loss:   610.4139 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  54 - Loss:   942.6562 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  55 - Loss:   884.6483 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  56 - Loss:   477.8154 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  57 - Loss:   760.7381 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  58 - Loss:   658.9032 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  59 - Loss:   605.3015 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  60 - Loss:   505.1296 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  61 - Loss:   441.9346 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  62 - Loss:   459.3076 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  63 - Loss:   711.9521 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  64 - Loss:   922.6836 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  65 - Loss:   534.8011 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  66 - Loss:   446.0025 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  67 - Loss:   756.5646 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  68 - Loss:   501.3320 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  69 - Loss:   811.6408 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  70 - Loss:   688.6850 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  71 - Loss:   554.8738 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  72 - Loss:   547.6702 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  73 - Loss:   637.4085 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  74 - Loss:   456.6037 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  75 - Loss:   493.2323 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  76 - Loss:   867.8690 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  77 - Loss:   533.8657 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  78 - Loss:   336.1203 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  79 - Loss:   628.0657 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  80 - Loss:   513.2313 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  81 - Loss:   539.5837 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  82 - Loss:   768.5812 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  83 - Loss:   653.9089 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  84 - Loss:   519.1048 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  85 - Loss:   603.9779 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  86 - Loss:   894.1771 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  87 - Loss:   469.3137 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  88 - Loss:   684.5190 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch  89 - Loss:   746.5713 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  90 - Loss:   835.4133 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  91 - Loss:   676.4830 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  92 - Loss:   291.5706 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  93 - Loss:   478.4172 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  94 - Loss:   458.7906 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  95 - Loss:   780.0290 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  96 - Loss:   453.4037 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  97 - Loss:   548.7076 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch  98 - Loss:   533.2267 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch  99 - Loss:   528.5447 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 100 - Loss:   560.2677 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 101 - Loss:   608.3739 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 102 - Loss:   551.7220 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 103 - Loss:   702.2415 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 104 - Loss:   691.4176 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 105 - Loss:   582.5879 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 106 - Loss:   569.5897 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 107 - Loss:   510.2733 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 108 - Loss:   673.3683 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 109 - Loss:   682.5698 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 110 - Loss:   587.4679 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 111 - Loss:   649.9832 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 112 - Loss:   540.5342 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 113 - Loss:   551.0364 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 114 - Loss:   582.9414 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 115 - Loss:   685.3215 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 116 - Loss:   601.9999 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 117 - Loss:   654.6843 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 118 - Loss:   453.1390 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 119 - Loss:   540.6769 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 120 - Loss:   635.2733 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 121 - Loss:   452.5603 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 122 - Loss:   654.7030 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 123 - Loss:   377.4293 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 124 - Loss:   647.3989 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 125 - Loss:   654.2142 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 126 - Loss:   638.7067 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 127 - Loss:   586.3925 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 128 - Loss:   508.4072 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 129 - Loss:   464.2636 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 130 - Loss:   558.2028 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 131 - Loss:   671.3012 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 132 - Loss:   671.0923 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 133 - Loss:   696.8809 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 134 - Loss:   660.0706 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 135 - Loss:   683.8000 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 136 - Loss:   654.0154 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 137 - Loss:   531.7616 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 138 - Loss:   791.9650 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 139 - Loss:   547.7280 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 140 - Loss:   526.5349 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 141 - Loss:   465.3045 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 142 - Loss:   644.5106 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 143 - Loss:   427.1367 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 144 - Loss:   376.3454 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 145 - Loss:   633.2666 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 146 - Loss:   782.0031 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 147 - Loss:   662.0808 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 148 - Loss:   447.7701 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 149 - Loss:   377.6071 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 150 - Loss:   866.4158 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 151 - Loss:   574.7352 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 152 - Loss:   349.2762 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 153 - Loss:   313.2690 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 154 - Loss:   519.5140 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 155 - Loss:   728.8005 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 156 - Loss:   483.5344 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 157 - Loss:   725.7477 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 158 - Loss:   601.5377 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 159 - Loss:   605.5068 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 160 - Loss:   467.9688 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 161 - Loss:   743.8970 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 162 - Loss:   650.8063 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 163 - Loss:   500.9332 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 164 - Loss:   635.0919 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 165 - Loss:   436.0544 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 166 - Loss:   601.3585 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 167 - Loss:   370.2261 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 168 - Loss:   450.8951 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 169 - Loss:   438.2039 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 170 - Loss:   880.3035 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 171 - Loss:   323.5471 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 172 - Loss:   437.2924 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 173 - Loss:   621.9650 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 174 - Loss:   617.4453 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 175 - Loss:   717.8097 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 176 - Loss:   521.0098 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 177 - Loss:   459.9594 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 178 - Loss:   570.6748 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 179 - Loss:   562.6284 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 180 - Loss:   886.0530 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 181 - Loss:   420.1981 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 182 - Loss:   730.2693 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 183 - Loss:   730.0320 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 184 - Loss:   642.4493 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 185 - Loss:   439.6170 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 186 - Loss:   448.0421 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 187 - Loss:   478.9499 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 188 - Loss:   485.5157 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 189 - Loss:   525.1932 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 190 - Loss:   674.5520 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 191 - Loss:   670.2773 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 192 - Loss:   403.2032 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 193 - Loss:   466.0948 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 194 - Loss:   806.8473 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 195 - Loss:   602.1064 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 196 - Loss:   476.6136 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 197 - Loss:   414.7377 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 198 - Loss:   601.9094 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 199 - Loss:   504.4594 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 200 - Loss:   725.1102 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 201 - Loss:   334.6348 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 202 - Loss:   656.3874 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 203 - Loss:   470.9941 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 204 - Loss:   677.7426 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 205 - Loss:   363.2675 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 206 - Loss:   700.5654 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 207 - Loss:   540.5257 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 208 - Loss:   805.6361 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 209 - Loss:   591.8206 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 210 - Loss:   411.9949 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 211 - Loss:   715.7400 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 212 - Loss:   662.0851 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 213 - Loss:   531.9988 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 214 - Loss:   488.3823 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 215 - Loss:   687.5192 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 216 - Loss:   634.7768 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 217 - Loss:   563.2092 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 218 - Loss:   435.3319 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 219 - Loss:   472.4020 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 220 - Loss:   493.1143 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 221 - Loss:   567.2442 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 222 - Loss:   417.5166 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 223 - Loss:   625.0172 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 224 - Loss:   457.5175 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 225 - Loss:   664.5849 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 226 - Loss:   509.8374 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 227 - Loss:   763.5012 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 228 - Loss:   436.7022 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 229 - Loss:   874.4514 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 230 - Loss:   532.4380 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 231 - Loss:   616.3624 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 232 - Loss:   427.2101 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 233 - Loss:   701.6844 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 234 - Loss:   499.8856 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 235 - Loss:   396.3287 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 236 - Loss:   481.6745 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 237 - Loss:   475.1760 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 238 - Loss:   558.0085 Validation Accuracy: 0.812500\n",
      "Epoch  4, Batch 239 - Loss:   421.2400 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 240 - Loss:   547.9059 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 241 - Loss:   659.1653 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 242 - Loss:   628.3812 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 243 - Loss:   601.7595 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 244 - Loss:   425.7969 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 245 - Loss:   628.7384 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 246 - Loss:   588.9747 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 247 - Loss:   366.1890 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 248 - Loss:   593.3903 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 249 - Loss:   484.2315 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 250 - Loss:   583.3430 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 251 - Loss:   535.1537 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 252 - Loss:   531.3057 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 253 - Loss:   754.3416 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 254 - Loss:   532.3213 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 255 - Loss:   738.4406 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 256 - Loss:   384.6134 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 257 - Loss:   388.0580 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 258 - Loss:   700.6055 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 259 - Loss:   616.1469 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 260 - Loss:   388.7100 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 261 - Loss:   533.6215 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 262 - Loss:   495.5286 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 263 - Loss:   467.7544 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 264 - Loss:   447.8453 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 265 - Loss:   606.3932 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 266 - Loss:   528.2854 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 267 - Loss:   465.1590 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 268 - Loss:   572.6241 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 269 - Loss:   477.5178 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 270 - Loss:   521.1526 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 271 - Loss:   602.5123 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 272 - Loss:   843.3835 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 273 - Loss:   453.3051 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 274 - Loss:   368.5787 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 275 - Loss:   638.7899 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 276 - Loss:   479.6147 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 277 - Loss:   264.1259 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 278 - Loss:   686.5374 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 279 - Loss:   624.9759 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 280 - Loss:   587.6047 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 281 - Loss:   604.4774 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 282 - Loss:   492.8854 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 283 - Loss:   703.9755 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 284 - Loss:   295.9439 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 285 - Loss:   616.4510 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 286 - Loss:   732.1157 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 287 - Loss:   667.9092 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 288 - Loss:   791.8525 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 289 - Loss:   538.8172 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 290 - Loss:   588.9833 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 291 - Loss:   672.2485 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 292 - Loss:   358.2498 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 293 - Loss:   905.8069 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 294 - Loss:   550.4590 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 295 - Loss:   529.3820 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 296 - Loss:   666.0464 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 297 - Loss:   820.5806 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 298 - Loss:   871.2035 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 299 - Loss:   510.2633 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 300 - Loss:   516.4739 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 301 - Loss:   315.0172 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 302 - Loss:   586.9973 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 303 - Loss:   528.1954 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 304 - Loss:   343.0797 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 305 - Loss:   339.8240 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 306 - Loss:   625.8649 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 307 - Loss:   443.4339 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 308 - Loss:   433.7352 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 309 - Loss:   276.4371 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 310 - Loss:   516.9438 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 311 - Loss:   491.6870 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 312 - Loss:   471.9862 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 313 - Loss:   569.5121 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 314 - Loss:   407.2168 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 315 - Loss:   373.5653 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 316 - Loss:   744.0396 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 317 - Loss:   469.7865 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 318 - Loss:   867.3410 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 319 - Loss:   556.3386 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 320 - Loss:   413.6877 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 321 - Loss:   368.5016 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 322 - Loss:   360.7951 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 323 - Loss:   322.8237 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 324 - Loss:   594.1438 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 325 - Loss:   527.8201 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 326 - Loss:   681.5569 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 327 - Loss:   639.7551 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 328 - Loss:   528.1467 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 329 - Loss:   426.6277 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 330 - Loss:   590.0356 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 331 - Loss:   440.1650 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 332 - Loss:   454.8143 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 333 - Loss:   459.5522 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 334 - Loss:   539.8472 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 335 - Loss:   420.3346 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 336 - Loss:   444.7017 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 337 - Loss:   538.0226 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 338 - Loss:   402.1254 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 339 - Loss:   347.6121 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 340 - Loss:   358.9705 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 341 - Loss:   595.7521 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 342 - Loss:   486.1359 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 343 - Loss:   480.1639 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 344 - Loss:   493.5219 Validation Accuracy: 0.808594\n",
      "Epoch  4, Batch 345 - Loss:   831.8395 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 346 - Loss:   465.0723 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 347 - Loss:   509.3119 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 348 - Loss:   578.5069 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 349 - Loss:   425.1246 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 350 - Loss:   748.0239 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 351 - Loss:   346.7765 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 352 - Loss:   718.6362 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 353 - Loss:   448.3797 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 354 - Loss:   444.3101 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 355 - Loss:   607.8784 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 356 - Loss:   624.8320 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 357 - Loss:   541.0426 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 358 - Loss:   354.2413 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 359 - Loss:   349.7571 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 360 - Loss:   495.1959 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 361 - Loss:   561.2630 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 362 - Loss:   253.8074 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 363 - Loss:   555.1538 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 364 - Loss:   237.4183 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 365 - Loss:   524.1475 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 366 - Loss:   540.9988 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 367 - Loss:   491.8591 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 368 - Loss:   650.1227 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 369 - Loss:   540.2593 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 370 - Loss:   422.7013 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 371 - Loss:   688.8628 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 372 - Loss:   559.2153 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 373 - Loss:   581.6114 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 374 - Loss:   428.8683 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 375 - Loss:   454.6699 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 376 - Loss:   549.0211 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 377 - Loss:   488.3826 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 378 - Loss:   391.8613 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 379 - Loss:   720.8370 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 380 - Loss:   220.3347 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 381 - Loss:   481.4711 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 382 - Loss:   577.8889 Validation Accuracy: 0.785156\n",
      "Epoch  4, Batch 383 - Loss:   591.0541 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 384 - Loss:   360.7148 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 385 - Loss:   826.8288 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 386 - Loss:   452.4005 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 387 - Loss:   587.8137 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 388 - Loss:   412.2901 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 389 - Loss:   677.0728 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 390 - Loss:   346.7739 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 391 - Loss:   634.4260 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 392 - Loss:   772.0582 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 393 - Loss:   870.9763 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 394 - Loss:   777.5275 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 395 - Loss:   450.7283 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 396 - Loss:   520.5991 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 397 - Loss:   387.5692 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 398 - Loss:   660.6739 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 399 - Loss:   508.9376 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 400 - Loss:   554.0701 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 401 - Loss:   456.6850 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 402 - Loss:   498.5659 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 403 - Loss:   508.7999 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 404 - Loss:   358.8672 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 405 - Loss:   571.9587 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 406 - Loss:   614.3792 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 407 - Loss:   582.8687 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 408 - Loss:   590.5675 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 409 - Loss:   561.3826 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 410 - Loss:   717.1794 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 411 - Loss:   613.6766 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 412 - Loss:   566.8158 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 413 - Loss:   354.5863 Validation Accuracy: 0.789062\n",
      "Epoch  4, Batch 414 - Loss:   547.1779 Validation Accuracy: 0.792969\n",
      "Epoch  4, Batch 415 - Loss:   550.4917 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 416 - Loss:   420.8536 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 417 - Loss:   382.3311 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 418 - Loss:   410.8990 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 419 - Loss:   615.5234 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 420 - Loss:   894.2280 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 421 - Loss:   793.5361 Validation Accuracy: 0.804688\n",
      "Epoch  4, Batch 422 - Loss:   478.5076 Validation Accuracy: 0.796875\n",
      "Epoch  4, Batch 423 - Loss:   583.4340 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 424 - Loss:   443.9053 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 425 - Loss:   316.8490 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 426 - Loss:   377.1701 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 427 - Loss:   616.8343 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 428 - Loss:   559.1609 Validation Accuracy: 0.800781\n",
      "Epoch  4, Batch 429 - Loss:   335.7901 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch   1 - Loss:   522.0807 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch   2 - Loss:   560.5109 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch   3 - Loss:   518.6158 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch   4 - Loss:   566.7769 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch   5 - Loss:   505.7466 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch   6 - Loss:   402.9863 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch   7 - Loss:   614.7080 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch   8 - Loss:   698.7145 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch   9 - Loss:   397.5131 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  10 - Loss:   788.8376 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  11 - Loss:   457.3033 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch  12 - Loss:   536.5741 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  13 - Loss:   543.2764 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  14 - Loss:   371.9166 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  15 - Loss:   690.1926 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  16 - Loss:   691.9775 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  17 - Loss:   460.1284 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  18 - Loss:   562.2485 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  19 - Loss:   287.3979 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  20 - Loss:   452.2086 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  21 - Loss:   345.6162 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  22 - Loss:   370.5418 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch  23 - Loss:   302.6698 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  24 - Loss:   544.7935 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  25 - Loss:   725.7717 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  26 - Loss:   489.2301 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  27 - Loss:   354.7495 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  28 - Loss:   491.7110 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch  29 - Loss:   799.5558 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  30 - Loss:   568.0120 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  31 - Loss:   432.0314 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  32 - Loss:   706.7440 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  33 - Loss:   578.6958 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  34 - Loss:   422.3114 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  35 - Loss:   676.7627 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  36 - Loss:   387.2117 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  37 - Loss:   652.9308 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  38 - Loss:   546.4282 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  39 - Loss:   391.5466 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  40 - Loss:   472.2927 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  41 - Loss:   463.6431 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  42 - Loss:   426.7419 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  43 - Loss:   481.1405 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  44 - Loss:   401.6245 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  45 - Loss:   413.4815 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  46 - Loss:   506.5051 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  47 - Loss:   402.9308 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  48 - Loss:   460.7438 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  49 - Loss:   844.7201 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  50 - Loss:   477.1915 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  51 - Loss:   428.3286 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  52 - Loss:   661.8719 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  53 - Loss:   577.3582 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  54 - Loss:   347.1824 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  55 - Loss:   401.1528 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  56 - Loss:   502.0110 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  57 - Loss:   414.8390 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  58 - Loss:   595.2303 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  59 - Loss:   498.6889 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  60 - Loss:   551.8686 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  61 - Loss:   385.8231 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  62 - Loss:   540.0591 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  63 - Loss:   496.1181 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  64 - Loss:   338.2346 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  65 - Loss:   469.3694 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  66 - Loss:   744.9475 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  67 - Loss:   314.3450 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  68 - Loss:   626.5900 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  69 - Loss:   732.0370 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  70 - Loss:   461.0400 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  71 - Loss:   535.9610 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  72 - Loss:   319.3645 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  73 - Loss:   443.7796 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  74 - Loss:   610.3693 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  75 - Loss:   888.2778 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  76 - Loss:   569.8367 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  77 - Loss:   496.1274 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch  78 - Loss:   752.9712 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  79 - Loss:   458.3807 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  80 - Loss:   380.7918 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  81 - Loss:   484.6496 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  82 - Loss:   365.6786 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  83 - Loss:   594.1092 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  84 - Loss:   664.0399 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  85 - Loss:   543.5630 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  86 - Loss:   508.3699 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  87 - Loss:   450.6944 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  88 - Loss:   457.6021 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch  89 - Loss:   461.8555 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  90 - Loss:   356.0904 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  91 - Loss:   660.9252 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  92 - Loss:   501.2220 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  93 - Loss:   505.5840 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  94 - Loss:   593.6757 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  95 - Loss:   394.7187 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch  96 - Loss:   650.6112 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  97 - Loss:   546.3631 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  98 - Loss:   599.2701 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch  99 - Loss:   386.2451 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 100 - Loss:   325.2428 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 101 - Loss:   494.3185 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 102 - Loss:   468.9103 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 103 - Loss:   537.8865 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 104 - Loss:   600.9161 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 105 - Loss:   594.6685 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 106 - Loss:   448.0181 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 107 - Loss:   688.0416 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 108 - Loss:   445.7129 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 109 - Loss:   434.7130 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 110 - Loss:   410.6715 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 111 - Loss:   433.4759 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 112 - Loss:   473.7707 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 113 - Loss:   794.0463 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 114 - Loss:   420.0414 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 115 - Loss:   496.5122 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 116 - Loss:   638.7524 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 117 - Loss:   612.6969 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 118 - Loss:   494.9935 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 119 - Loss:   390.3018 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 120 - Loss:   526.1497 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 121 - Loss:   533.4425 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 122 - Loss:   454.6689 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 123 - Loss:   507.7426 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 124 - Loss:   548.6848 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 125 - Loss:   440.0107 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 126 - Loss:   307.1039 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 127 - Loss:   638.8456 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 128 - Loss:   343.0505 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 129 - Loss:   605.6428 Validation Accuracy: 0.785156\n",
      "Epoch  5, Batch 130 - Loss:   294.5577 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 131 - Loss:   443.9174 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 132 - Loss:   243.9372 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 133 - Loss:   522.1681 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 134 - Loss:   253.6190 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 135 - Loss:   486.8788 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 136 - Loss:   408.3414 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 137 - Loss:   442.0590 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 138 - Loss:   472.7674 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 139 - Loss:   328.1939 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 140 - Loss:   366.5414 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 141 - Loss:   532.0113 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 142 - Loss:   444.2108 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 143 - Loss:   381.0475 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 144 - Loss:   253.7025 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 145 - Loss:   491.4232 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 146 - Loss:   336.4069 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 147 - Loss:   501.3317 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 148 - Loss:   583.5736 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 149 - Loss:   454.5776 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 150 - Loss:   477.7090 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 151 - Loss:   562.8680 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 152 - Loss:   399.9537 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 153 - Loss:   428.9972 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 154 - Loss:   667.1986 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 155 - Loss:   431.8565 Validation Accuracy: 0.785156\n",
      "Epoch  5, Batch 156 - Loss:   409.0907 Validation Accuracy: 0.785156\n",
      "Epoch  5, Batch 157 - Loss:   414.1306 Validation Accuracy: 0.785156\n",
      "Epoch  5, Batch 158 - Loss:   410.7522 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 159 - Loss:   377.9908 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 160 - Loss:   264.6391 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 161 - Loss:   622.1458 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 162 - Loss:   551.9683 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 163 - Loss:   398.4893 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 164 - Loss:   481.0517 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 165 - Loss:   545.6286 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 166 - Loss:   556.2286 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 167 - Loss:   421.1798 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 168 - Loss:   545.3786 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 169 - Loss:   245.1900 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 170 - Loss:   409.1012 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 171 - Loss:   490.1501 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 172 - Loss:   709.1276 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 173 - Loss:   437.9691 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 174 - Loss:   372.7942 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 175 - Loss:   271.6216 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 176 - Loss:   475.5794 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 177 - Loss:   511.6775 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 178 - Loss:   374.4870 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 179 - Loss:   472.1755 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 180 - Loss:   554.8088 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 181 - Loss:   405.0249 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 182 - Loss:   377.4827 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 183 - Loss:   864.8967 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 184 - Loss:   509.2432 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 185 - Loss:   485.8121 Validation Accuracy: 0.789062\n",
      "Epoch  5, Batch 186 - Loss:   518.2434 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 187 - Loss:   433.7850 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 188 - Loss:   393.9758 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 189 - Loss:   707.6823 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 190 - Loss:   360.2129 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 191 - Loss:   605.4572 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 192 - Loss:   451.2920 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 193 - Loss:   568.7559 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 194 - Loss:   449.3829 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 195 - Loss:   538.6255 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 196 - Loss:   561.4873 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 197 - Loss:   426.1605 Validation Accuracy: 0.792969\n",
      "Epoch  5, Batch 198 - Loss:   486.6907 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 199 - Loss:   611.8642 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 200 - Loss:   439.7780 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 201 - Loss:   428.4504 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 202 - Loss:   253.9730 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 203 - Loss:   436.0875 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 204 - Loss:   458.0272 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 205 - Loss:   710.1462 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 206 - Loss:   376.0042 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 207 - Loss:   531.5276 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 208 - Loss:   459.8920 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 209 - Loss:   562.3363 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 210 - Loss:   578.9319 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 211 - Loss:   239.2264 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 212 - Loss:   391.7514 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 213 - Loss:   512.8253 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 214 - Loss:   556.3999 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 215 - Loss:   393.3953 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 216 - Loss:   386.8758 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 217 - Loss:   557.2467 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 218 - Loss:   434.3937 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 219 - Loss:   398.6219 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 220 - Loss:   533.8446 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 221 - Loss:   569.2903 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 222 - Loss:   348.2271 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 223 - Loss:   585.8268 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 224 - Loss:   478.4549 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 225 - Loss:   386.2163 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 226 - Loss:   416.0809 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 227 - Loss:   525.2705 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 228 - Loss:   567.7588 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 229 - Loss:   259.5654 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 230 - Loss:   589.9315 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 231 - Loss:   371.2965 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 232 - Loss:   644.1280 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 233 - Loss:   411.4111 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 234 - Loss:   324.4316 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 235 - Loss:   493.5055 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 236 - Loss:   350.6758 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 237 - Loss:   546.4436 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 238 - Loss:   453.6667 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 239 - Loss:   630.4694 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 240 - Loss:   281.8370 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 241 - Loss:   285.4444 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 242 - Loss:   550.6670 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 243 - Loss:   494.4977 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 244 - Loss:   580.5234 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 245 - Loss:   466.0821 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 246 - Loss:   366.8654 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 247 - Loss:   320.6971 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 248 - Loss:   559.6947 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 249 - Loss:   374.3766 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 250 - Loss:   536.6082 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 251 - Loss:   615.1068 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 252 - Loss:   487.2673 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 253 - Loss:   195.1086 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 254 - Loss:   586.5488 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 255 - Loss:   493.6845 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 256 - Loss:   441.7381 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 257 - Loss:   404.9975 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 258 - Loss:   545.7490 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 259 - Loss:   383.6799 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 260 - Loss:   643.7977 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 261 - Loss:   262.5339 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 262 - Loss:   509.9290 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 263 - Loss:   496.0473 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 264 - Loss:   562.1457 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 265 - Loss:   546.5687 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 266 - Loss:   439.5758 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 267 - Loss:   605.7318 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 268 - Loss:   327.5804 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 269 - Loss:   381.8231 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 270 - Loss:   450.4981 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 271 - Loss:   446.1629 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 272 - Loss:   390.3747 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 273 - Loss:   318.8060 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 274 - Loss:   498.1517 Validation Accuracy: 0.796875\n",
      "Epoch  5, Batch 275 - Loss:   555.3265 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 276 - Loss:   402.6759 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 277 - Loss:   494.1951 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 278 - Loss:   443.1793 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 279 - Loss:   422.6043 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 280 - Loss:   305.2182 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 281 - Loss:   532.2684 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 282 - Loss:   408.2926 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 283 - Loss:   431.6233 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 284 - Loss:   442.2784 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 285 - Loss:   369.6159 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 286 - Loss:   424.4836 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 287 - Loss:   453.9873 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 288 - Loss:   442.9369 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 289 - Loss:   500.2441 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 290 - Loss:   531.2873 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 291 - Loss:   551.6178 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 292 - Loss:   451.7032 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 293 - Loss:   473.4506 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 294 - Loss:   385.6589 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 295 - Loss:   353.5326 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 296 - Loss:   590.5837 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 297 - Loss:   624.8317 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 298 - Loss:   562.2499 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 299 - Loss:   615.1840 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 300 - Loss:   289.2174 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 301 - Loss:   451.6736 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 302 - Loss:   438.2062 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 303 - Loss:   283.8648 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 304 - Loss:   313.5403 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 305 - Loss:   377.0947 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 306 - Loss:   393.7902 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 307 - Loss:   455.5992 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 308 - Loss:   348.6068 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 309 - Loss:   415.4955 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 310 - Loss:   343.6777 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 311 - Loss:   284.6621 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 312 - Loss:   476.8163 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 313 - Loss:   391.6584 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 314 - Loss:   308.4817 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 315 - Loss:   438.1458 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 316 - Loss:   386.3373 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 317 - Loss:   445.3680 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 318 - Loss:   460.2343 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 319 - Loss:   578.8347 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 320 - Loss:   674.2429 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 321 - Loss:   343.3691 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 322 - Loss:   445.0660 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 323 - Loss:   403.6945 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 324 - Loss:   424.0567 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 325 - Loss:   418.0889 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 326 - Loss:   454.2412 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 327 - Loss:   390.1707 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 328 - Loss:   580.1078 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 329 - Loss:   431.0048 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 330 - Loss:   342.5822 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 331 - Loss:   313.6610 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 332 - Loss:   417.9701 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 333 - Loss:   485.8814 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 334 - Loss:   504.1761 Validation Accuracy: 0.804688\n",
      "Epoch  5, Batch 335 - Loss:   312.5193 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 336 - Loss:   527.6484 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 337 - Loss:   686.9615 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 338 - Loss:   385.6426 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 339 - Loss:   512.7523 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 340 - Loss:   367.7405 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 341 - Loss:   406.5580 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 342 - Loss:   403.8636 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 343 - Loss:   397.4872 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 344 - Loss:   383.4028 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 345 - Loss:   436.1078 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 346 - Loss:   445.2794 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 347 - Loss:   457.1972 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 348 - Loss:   438.9230 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 349 - Loss:   549.2898 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 350 - Loss:   443.6943 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 351 - Loss:   431.9338 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 352 - Loss:   314.1716 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 353 - Loss:   268.7165 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 354 - Loss:   393.7739 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 355 - Loss:   487.4227 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 356 - Loss:   562.9477 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 357 - Loss:   340.3590 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 358 - Loss:   511.1234 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 359 - Loss:   623.5764 Validation Accuracy: 0.800781\n",
      "Epoch  5, Batch 360 - Loss:   465.7085 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 361 - Loss:   476.8913 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 362 - Loss:   478.8749 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 363 - Loss:   479.1635 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 364 - Loss:   416.8917 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 365 - Loss:   582.0836 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 366 - Loss:   594.4897 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 367 - Loss:   479.9021 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 368 - Loss:   542.9250 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 369 - Loss:   578.4547 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 370 - Loss:   399.2338 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 371 - Loss:   448.0411 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 372 - Loss:   515.3499 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 373 - Loss:   409.2877 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 374 - Loss:   402.6064 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 375 - Loss:   248.0073 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 376 - Loss:   482.5634 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 377 - Loss:   511.5826 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 378 - Loss:   343.0603 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 379 - Loss:   535.8364 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 380 - Loss:   604.1135 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 381 - Loss:   506.6679 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 382 - Loss:   469.3280 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 383 - Loss:   356.6862 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 384 - Loss:   601.7545 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 385 - Loss:   290.5789 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 386 - Loss:   407.2942 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 387 - Loss:   347.7148 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 388 - Loss:   471.8823 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 389 - Loss:   414.1688 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 390 - Loss:   531.2369 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 391 - Loss:   418.1362 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 392 - Loss:   467.3851 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 393 - Loss:   365.3704 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 394 - Loss:   282.5029 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 395 - Loss:   520.1694 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 396 - Loss:   449.3766 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 397 - Loss:   265.8626 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 398 - Loss:   456.2269 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 399 - Loss:   532.1755 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 400 - Loss:   327.2313 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 401 - Loss:   471.3573 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 402 - Loss:   446.5729 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 403 - Loss:   559.5005 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 404 - Loss:   498.7469 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 405 - Loss:   509.7056 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 406 - Loss:   616.4477 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 407 - Loss:   237.0442 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 408 - Loss:   197.4506 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 409 - Loss:   251.7255 Validation Accuracy: 0.835938\n",
      "Epoch  5, Batch 410 - Loss:   521.3062 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 411 - Loss:   319.0803 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 412 - Loss:   433.4004 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 413 - Loss:   652.8604 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 414 - Loss:   341.3906 Validation Accuracy: 0.832031\n",
      "Epoch  5, Batch 415 - Loss:   493.1764 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 416 - Loss:   315.8259 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 417 - Loss:   455.0664 Validation Accuracy: 0.828125\n",
      "Epoch  5, Batch 418 - Loss:   521.6793 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 419 - Loss:   276.2374 Validation Accuracy: 0.824219\n",
      "Epoch  5, Batch 420 - Loss:   508.6178 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 421 - Loss:   524.2592 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 422 - Loss:   456.7462 Validation Accuracy: 0.808594\n",
      "Epoch  5, Batch 423 - Loss:   539.4036 Validation Accuracy: 0.812500\n",
      "Epoch  5, Batch 424 - Loss:   395.8623 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 425 - Loss:   382.5107 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 426 - Loss:   339.7458 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 427 - Loss:   475.5871 Validation Accuracy: 0.820312\n",
      "Epoch  5, Batch 428 - Loss:   308.1233 Validation Accuracy: 0.816406\n",
      "Epoch  5, Batch 429 - Loss:   330.4669 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch   1 - Loss:   441.2148 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch   2 - Loss:   341.3561 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch   3 - Loss:   513.4206 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch   4 - Loss:   585.6567 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch   5 - Loss:   427.0514 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch   6 - Loss:   345.7126 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch   7 - Loss:   620.1061 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch   8 - Loss:   241.0907 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch   9 - Loss:   439.6725 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  10 - Loss:   455.9332 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  11 - Loss:   327.6492 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  12 - Loss:   498.9226 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  13 - Loss:   445.2598 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  14 - Loss:   390.8924 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  15 - Loss:   519.0703 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  16 - Loss:   477.4885 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  17 - Loss:   222.3033 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  18 - Loss:   393.2719 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  19 - Loss:   483.2122 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  20 - Loss:   277.8578 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  21 - Loss:   481.0892 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  22 - Loss:   431.3177 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  23 - Loss:   318.2928 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  24 - Loss:   443.1063 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  25 - Loss:   396.0116 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  26 - Loss:   419.2406 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch  27 - Loss:   405.3191 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  28 - Loss:   446.4056 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch  29 - Loss:   394.2204 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  30 - Loss:   365.9404 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch  31 - Loss:   364.3434 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  32 - Loss:   440.7596 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  33 - Loss:   397.7726 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  34 - Loss:   482.4763 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  35 - Loss:   544.9969 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch  36 - Loss:   706.1222 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  37 - Loss:   388.1685 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  38 - Loss:   369.2228 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  39 - Loss:   260.6707 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  40 - Loss:   262.9619 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  41 - Loss:   598.6207 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  42 - Loss:   266.4096 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  43 - Loss:   462.2912 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  44 - Loss:   418.2738 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch  45 - Loss:   473.8009 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  46 - Loss:   424.8911 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  47 - Loss:   372.8152 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  48 - Loss:   284.7708 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  49 - Loss:   496.2233 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  50 - Loss:   445.2267 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  51 - Loss:   370.5316 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  52 - Loss:   214.0634 Validation Accuracy: 0.828125\n",
      "Epoch  6, Batch  53 - Loss:   284.1588 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  54 - Loss:   299.1429 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  55 - Loss:   286.7029 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  56 - Loss:   551.1540 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  57 - Loss:   576.7136 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  58 - Loss:   381.0510 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  59 - Loss:   447.8911 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  60 - Loss:   277.7599 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  61 - Loss:   281.4153 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  62 - Loss:   342.2167 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  63 - Loss:   666.8047 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  64 - Loss:   425.8988 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  65 - Loss:   396.7991 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  66 - Loss:   321.1964 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  67 - Loss:   379.5178 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  68 - Loss:   582.4188 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  69 - Loss:   404.7808 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  70 - Loss:   496.7202 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  71 - Loss:   414.0460 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  72 - Loss:   430.0931 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  73 - Loss:   433.6891 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  74 - Loss:   276.6772 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  75 - Loss:   472.8676 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  76 - Loss:   497.5572 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  77 - Loss:   464.8748 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  78 - Loss:   274.7591 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  79 - Loss:   375.0961 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  80 - Loss:   405.9138 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  81 - Loss:   503.8146 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  82 - Loss:   552.2506 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  83 - Loss:   636.1251 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  84 - Loss:   383.1577 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  85 - Loss:   323.2281 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  86 - Loss:   267.1412 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  87 - Loss:   420.6787 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  88 - Loss:   371.4872 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  89 - Loss:   358.7620 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  90 - Loss:   568.4875 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  91 - Loss:   311.6505 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  92 - Loss:   319.1128 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  93 - Loss:   487.4805 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch  94 - Loss:   634.6840 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  95 - Loss:   510.4286 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch  96 - Loss:   741.2442 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  97 - Loss:   512.3228 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch  98 - Loss:   503.1060 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch  99 - Loss:   542.8738 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 100 - Loss:   391.3375 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 101 - Loss:   319.1428 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 102 - Loss:   582.9551 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 103 - Loss:   425.0355 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 104 - Loss:   505.4881 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 105 - Loss:   418.9988 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 106 - Loss:   394.8038 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 107 - Loss:   324.8453 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 108 - Loss:   418.3914 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 109 - Loss:   333.7068 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 110 - Loss:   475.9532 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 111 - Loss:   498.7646 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 112 - Loss:   512.3042 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 113 - Loss:   412.9907 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 114 - Loss:   455.0388 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 115 - Loss:   384.9096 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 116 - Loss:   426.7380 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 117 - Loss:   465.2025 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 118 - Loss:   442.7535 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 119 - Loss:   440.1951 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 120 - Loss:   526.5848 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 121 - Loss:   263.5018 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 122 - Loss:   636.0312 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 123 - Loss:   509.7209 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 124 - Loss:   401.7177 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 125 - Loss:   504.8931 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 126 - Loss:   326.4070 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 127 - Loss:   377.0255 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 128 - Loss:   448.7354 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 129 - Loss:   360.5386 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 130 - Loss:   496.6264 Validation Accuracy: 0.824219\n",
      "Epoch  6, Batch 131 - Loss:   365.4466 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 132 - Loss:   288.9793 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 133 - Loss:   440.3103 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 134 - Loss:   517.5052 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 135 - Loss:   308.4531 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 136 - Loss:   388.2458 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 137 - Loss:   431.9162 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 138 - Loss:   477.5883 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 139 - Loss:   425.5953 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 140 - Loss:   495.6487 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 141 - Loss:   412.8217 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 142 - Loss:   365.0566 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 143 - Loss:   577.0555 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 144 - Loss:   320.6836 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 145 - Loss:   428.3846 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 146 - Loss:   281.3173 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 147 - Loss:   590.6348 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 148 - Loss:   324.5013 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 149 - Loss:   312.5684 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 150 - Loss:   347.1693 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 151 - Loss:   464.1987 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 152 - Loss:   505.8112 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 153 - Loss:   298.7297 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 154 - Loss:   510.9938 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 155 - Loss:   216.8409 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 156 - Loss:   211.9078 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 157 - Loss:   351.2643 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 158 - Loss:   288.8941 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 159 - Loss:   414.5670 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 160 - Loss:   272.4742 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 161 - Loss:   512.4548 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 162 - Loss:   314.7115 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 163 - Loss:   419.1476 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 164 - Loss:   431.1880 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 165 - Loss:   457.0960 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 166 - Loss:   224.1588 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 167 - Loss:   365.8403 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 168 - Loss:   362.4795 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 169 - Loss:   463.8635 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 170 - Loss:   498.0607 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 171 - Loss:   430.2171 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 172 - Loss:   362.4016 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 173 - Loss:   455.1399 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 174 - Loss:   306.7803 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 175 - Loss:   428.7715 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 176 - Loss:   377.4059 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 177 - Loss:   384.1381 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 178 - Loss:   328.9999 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 179 - Loss:   468.8383 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 180 - Loss:   321.0269 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 181 - Loss:   394.3075 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 182 - Loss:   432.0753 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 183 - Loss:   463.9322 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 184 - Loss:   310.0184 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 185 - Loss:   386.0121 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 186 - Loss:   437.4156 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 187 - Loss:   337.4354 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 188 - Loss:   514.0425 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 189 - Loss:   392.7775 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 190 - Loss:   633.2294 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 191 - Loss:   402.8986 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 192 - Loss:   457.5814 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 193 - Loss:   353.6180 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 194 - Loss:   281.2315 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 195 - Loss:   257.6213 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 196 - Loss:   486.0138 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 197 - Loss:   310.0204 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 198 - Loss:   333.5827 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 199 - Loss:   374.5270 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 200 - Loss:   274.3052 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 201 - Loss:   488.3546 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 202 - Loss:   385.4020 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 203 - Loss:   426.9719 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 204 - Loss:   467.4200 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 205 - Loss:   444.9266 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 206 - Loss:   437.8190 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 207 - Loss:   485.4766 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 208 - Loss:   245.4282 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 209 - Loss:   560.3954 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 210 - Loss:   397.1561 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 211 - Loss:   483.5152 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 212 - Loss:   533.2801 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 213 - Loss:   366.3911 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 214 - Loss:   500.3506 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 215 - Loss:   477.9040 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 216 - Loss:   531.4952 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 217 - Loss:   325.9960 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 218 - Loss:   226.0400 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 219 - Loss:   510.3484 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 220 - Loss:   434.1591 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 221 - Loss:   437.0926 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 222 - Loss:   521.8933 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 223 - Loss:   184.8515 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 224 - Loss:   351.7644 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 225 - Loss:   414.2892 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 226 - Loss:   495.4309 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 227 - Loss:   249.0652 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 228 - Loss:   324.5828 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 229 - Loss:   328.9008 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 230 - Loss:   512.2366 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 231 - Loss:   350.0976 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 232 - Loss:   524.4974 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 233 - Loss:   334.1649 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 234 - Loss:   313.0007 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 235 - Loss:   425.1039 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 236 - Loss:   434.9309 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 237 - Loss:   379.6126 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 238 - Loss:   330.0376 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 239 - Loss:   451.0883 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 240 - Loss:   544.4648 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 241 - Loss:   508.7573 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 242 - Loss:   333.0592 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 243 - Loss:   337.5063 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 244 - Loss:   285.5809 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 245 - Loss:   532.4921 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 246 - Loss:   434.3747 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 247 - Loss:   173.1028 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 248 - Loss:   434.2889 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 249 - Loss:   462.5962 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 250 - Loss:   369.6142 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 251 - Loss:   484.3008 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 252 - Loss:   324.7386 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 253 - Loss:   253.7765 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 254 - Loss:   372.6040 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 255 - Loss:   482.5103 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 256 - Loss:   663.2051 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 257 - Loss:   546.8231 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 258 - Loss:   548.6801 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 259 - Loss:   358.5927 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 260 - Loss:   370.8675 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 261 - Loss:   370.3984 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 262 - Loss:   706.2912 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 263 - Loss:   306.1570 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 264 - Loss:   281.7668 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 265 - Loss:   485.8170 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 266 - Loss:   480.3580 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 267 - Loss:   504.7451 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 268 - Loss:   503.9672 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 269 - Loss:   362.7387 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 270 - Loss:   533.9911 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 271 - Loss:   619.2935 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 272 - Loss:   438.1966 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 273 - Loss:   489.0474 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 274 - Loss:   307.6253 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 275 - Loss:   394.0963 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 276 - Loss:   359.2870 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 277 - Loss:   367.8793 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 278 - Loss:   384.3555 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 279 - Loss:   307.0905 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 280 - Loss:   325.5911 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 281 - Loss:   231.7070 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 282 - Loss:   416.0380 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 283 - Loss:   278.9203 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 284 - Loss:   523.8968 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 285 - Loss:   382.6369 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 286 - Loss:   378.0671 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 287 - Loss:   345.0691 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 288 - Loss:   390.9367 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 289 - Loss:   440.5295 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 290 - Loss:   318.7150 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 291 - Loss:   366.3813 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 292 - Loss:   241.8082 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 293 - Loss:   266.5686 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 294 - Loss:   435.7263 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 295 - Loss:   435.7563 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 296 - Loss:   482.6499 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 297 - Loss:   331.9581 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 298 - Loss:   487.8188 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 299 - Loss:   281.6165 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 300 - Loss:   549.6463 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 301 - Loss:   460.8278 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 302 - Loss:   271.6947 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 303 - Loss:   378.6215 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 304 - Loss:   333.7952 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 305 - Loss:   376.4419 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 306 - Loss:   431.3309 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 307 - Loss:   310.4940 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 308 - Loss:   321.1910 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 309 - Loss:   668.7134 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 310 - Loss:   211.9913 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 311 - Loss:   238.2179 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 312 - Loss:   449.2722 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 313 - Loss:   389.1414 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 314 - Loss:   411.0613 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 315 - Loss:   394.7877 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 316 - Loss:   467.2636 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 317 - Loss:   323.9771 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 318 - Loss:   396.0600 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 319 - Loss:   316.6235 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 320 - Loss:   284.3997 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 321 - Loss:   289.1358 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 322 - Loss:   340.3762 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 323 - Loss:   486.3275 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 324 - Loss:   275.4405 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 325 - Loss:   376.9744 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 326 - Loss:   207.6181 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 327 - Loss:   364.3962 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 328 - Loss:   460.0943 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 329 - Loss:   291.2602 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 330 - Loss:   229.1010 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 331 - Loss:   300.1556 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 332 - Loss:   316.0023 Validation Accuracy: 0.820312\n",
      "Epoch  6, Batch 333 - Loss:   435.6491 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 334 - Loss:   275.3232 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 335 - Loss:   508.9101 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 336 - Loss:   448.4415 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 337 - Loss:   429.5787 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 338 - Loss:   379.2493 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 339 - Loss:   558.8637 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 340 - Loss:   362.3770 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 341 - Loss:   447.4157 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 342 - Loss:   310.7077 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 343 - Loss:   480.4138 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 344 - Loss:   353.2061 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 345 - Loss:   228.1304 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 346 - Loss:   289.6527 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 347 - Loss:   364.6223 Validation Accuracy: 0.816406\n",
      "Epoch  6, Batch 348 - Loss:   317.8273 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 349 - Loss:   532.7249 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 350 - Loss:   382.1357 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 351 - Loss:   281.6769 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 352 - Loss:   422.5179 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 353 - Loss:   405.3818 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 354 - Loss:   303.9103 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 355 - Loss:   372.4972 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 356 - Loss:   381.1582 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 357 - Loss:   219.8403 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 358 - Loss:   361.1076 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 359 - Loss:   363.6785 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 360 - Loss:   513.6946 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 361 - Loss:   208.8442 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 362 - Loss:   304.9831 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 363 - Loss:   295.2727 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 364 - Loss:   408.3055 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 365 - Loss:   208.4023 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 366 - Loss:   404.2754 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 367 - Loss:   454.1727 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 368 - Loss:   306.1171 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 369 - Loss:   363.8502 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 370 - Loss:   421.7659 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 371 - Loss:   397.0893 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 372 - Loss:   447.1453 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 373 - Loss:   353.2847 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 374 - Loss:   365.5274 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 375 - Loss:   392.4746 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 376 - Loss:   445.5236 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 377 - Loss:   393.5516 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 378 - Loss:   235.2563 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 379 - Loss:   294.4385 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 380 - Loss:   228.8923 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 381 - Loss:   388.1327 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 382 - Loss:   398.2400 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 383 - Loss:   518.9670 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 384 - Loss:   280.2550 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 385 - Loss:   437.4189 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 386 - Loss:   385.5862 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 387 - Loss:   379.1216 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 388 - Loss:   352.0873 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 389 - Loss:   298.0842 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 390 - Loss:   276.5272 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 391 - Loss:   247.0115 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 392 - Loss:   268.8426 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 393 - Loss:   402.9813 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 394 - Loss:   499.4808 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 395 - Loss:   469.0477 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 396 - Loss:   320.3688 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 397 - Loss:   385.4477 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 398 - Loss:   299.1127 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 399 - Loss:   383.6585 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 400 - Loss:   469.1130 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 401 - Loss:   395.2823 Validation Accuracy: 0.812500\n",
      "Epoch  6, Batch 402 - Loss:   360.5323 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 403 - Loss:   213.6307 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 404 - Loss:   413.2221 Validation Accuracy: 0.808594\n",
      "Epoch  6, Batch 405 - Loss:   303.3288 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 406 - Loss:   297.3811 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 407 - Loss:   379.8402 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 408 - Loss:   493.9920 Validation Accuracy: 0.792969\n",
      "Epoch  6, Batch 409 - Loss:   340.3270 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 410 - Loss:   291.3634 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 411 - Loss:   334.1669 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 412 - Loss:   266.9504 Validation Accuracy: 0.792969\n",
      "Epoch  6, Batch 413 - Loss:   672.6713 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 414 - Loss:   527.9391 Validation Accuracy: 0.804688\n",
      "Epoch  6, Batch 415 - Loss:   510.8499 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 416 - Loss:   297.4915 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 417 - Loss:   405.8515 Validation Accuracy: 0.789062\n",
      "Epoch  6, Batch 418 - Loss:   259.6646 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 419 - Loss:   412.7181 Validation Accuracy: 0.800781\n",
      "Epoch  6, Batch 420 - Loss:   362.8029 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 421 - Loss:   377.0818 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 422 - Loss:   206.1652 Validation Accuracy: 0.792969\n",
      "Epoch  6, Batch 423 - Loss:   382.7146 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 424 - Loss:   349.5981 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 425 - Loss:   341.2792 Validation Accuracy: 0.789062\n",
      "Epoch  6, Batch 426 - Loss:   411.3757 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 427 - Loss:   364.1913 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 428 - Loss:   389.5466 Validation Accuracy: 0.796875\n",
      "Epoch  6, Batch 429 - Loss:   519.0067 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch   1 - Loss:   436.1928 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch   2 - Loss:   340.8193 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch   3 - Loss:   442.5486 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch   4 - Loss:   406.8205 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch   5 - Loss:   349.9805 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch   6 - Loss:   357.4345 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch   7 - Loss:   284.8061 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch   8 - Loss:   259.7445 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch   9 - Loss:   162.2027 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  10 - Loss:   311.4608 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  11 - Loss:   324.7760 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  12 - Loss:   261.2356 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  13 - Loss:   271.2621 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  14 - Loss:   328.3579 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  15 - Loss:   410.0179 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  16 - Loss:   358.4803 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  17 - Loss:   307.1775 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  18 - Loss:   426.5128 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  19 - Loss:   324.8268 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  20 - Loss:   392.7468 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  21 - Loss:   385.5101 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  22 - Loss:   547.1675 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  23 - Loss:   555.9351 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  24 - Loss:   343.1492 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  25 - Loss:   456.1783 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  26 - Loss:   317.2598 Validation Accuracy: 0.796875\n",
      "Epoch  7, Batch  27 - Loss:   309.0940 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  28 - Loss:   397.4628 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  29 - Loss:   323.3614 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch  30 - Loss:   462.8240 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  31 - Loss:   315.0810 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  32 - Loss:   353.9149 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  33 - Loss:   309.4828 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  34 - Loss:   492.1896 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  35 - Loss:   403.3553 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  36 - Loss:   371.0930 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  37 - Loss:   430.6097 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  38 - Loss:   292.4403 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  39 - Loss:   504.1530 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  40 - Loss:   465.9226 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  41 - Loss:   467.3156 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  42 - Loss:   244.6512 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  43 - Loss:   451.7137 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  44 - Loss:   235.9362 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  45 - Loss:   434.2352 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  46 - Loss:   527.9333 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  47 - Loss:   382.1483 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  48 - Loss:   431.7054 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  49 - Loss:   209.2607 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  50 - Loss:   171.6420 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  51 - Loss:   555.7062 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  52 - Loss:   311.1053 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  53 - Loss:   410.5841 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  54 - Loss:   411.0338 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  55 - Loss:   144.5542 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  56 - Loss:   437.8125 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  57 - Loss:   310.0591 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  58 - Loss:   411.9253 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  59 - Loss:   469.6886 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  60 - Loss:   483.9176 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  61 - Loss:   362.2648 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  62 - Loss:   458.1770 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  63 - Loss:   358.9484 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  64 - Loss:   371.7794 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  65 - Loss:   326.6641 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  66 - Loss:   162.1326 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  67 - Loss:   408.0581 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  68 - Loss:   389.3487 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  69 - Loss:   310.4963 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  70 - Loss:   602.9451 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  71 - Loss:   399.7417 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  72 - Loss:   357.0455 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  73 - Loss:   357.7368 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  74 - Loss:   254.8969 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  75 - Loss:   425.6368 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  76 - Loss:   336.1909 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  77 - Loss:   464.7498 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  78 - Loss:   379.2264 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  79 - Loss:   308.4810 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  80 - Loss:   258.2579 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  81 - Loss:   461.8087 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  82 - Loss:   320.9411 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  83 - Loss:   336.0384 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  84 - Loss:   362.9691 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  85 - Loss:   292.2536 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  86 - Loss:   265.8749 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  87 - Loss:   336.7775 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  88 - Loss:   491.0398 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  89 - Loss:   357.1067 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  90 - Loss:   349.4767 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  91 - Loss:   450.1710 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  92 - Loss:   264.2203 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  93 - Loss:   564.1746 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch  94 - Loss:   388.2341 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  95 - Loss:   586.0775 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch  96 - Loss:   476.5006 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  97 - Loss:   487.7691 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch  98 - Loss:   248.2150 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch  99 - Loss:   392.6620 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 100 - Loss:   286.7901 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 101 - Loss:   383.5412 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 102 - Loss:   364.0321 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 103 - Loss:   297.3481 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 104 - Loss:   246.8302 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 105 - Loss:   347.9155 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 106 - Loss:   447.2706 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 107 - Loss:   439.2357 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 108 - Loss:   272.0309 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 109 - Loss:   444.4180 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 110 - Loss:   189.4917 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 111 - Loss:   304.5765 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 112 - Loss:   337.3421 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 113 - Loss:   441.8396 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 114 - Loss:   259.5677 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 115 - Loss:   435.1682 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 116 - Loss:   380.6030 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 117 - Loss:   352.8381 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 118 - Loss:   282.8115 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 119 - Loss:   466.9868 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 120 - Loss:   277.2667 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 121 - Loss:   421.0493 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 122 - Loss:   311.1183 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 123 - Loss:   359.4038 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 124 - Loss:   421.2254 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 125 - Loss:   343.6144 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 126 - Loss:   402.2228 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 127 - Loss:   304.6490 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 128 - Loss:   424.9476 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 129 - Loss:   223.8974 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 130 - Loss:   331.9765 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 131 - Loss:   150.3834 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 132 - Loss:   307.5765 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 133 - Loss:   368.1509 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 134 - Loss:   394.2335 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 135 - Loss:   267.0980 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 136 - Loss:   452.3920 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 137 - Loss:   302.6047 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 138 - Loss:   493.1680 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 139 - Loss:   353.1490 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 140 - Loss:   284.9416 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 141 - Loss:   531.6385 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 142 - Loss:   436.1268 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 143 - Loss:   343.9875 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 144 - Loss:   388.8610 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 145 - Loss:   406.0518 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 146 - Loss:   415.8683 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 147 - Loss:   449.7979 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 148 - Loss:   326.1861 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 149 - Loss:   409.7103 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 150 - Loss:   283.5495 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 151 - Loss:   478.4557 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 152 - Loss:   384.7886 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 153 - Loss:   365.8134 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 154 - Loss:   386.5748 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 155 - Loss:   387.1209 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 156 - Loss:   256.8216 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 157 - Loss:   416.6663 Validation Accuracy: 0.796875\n",
      "Epoch  7, Batch 158 - Loss:   493.1615 Validation Accuracy: 0.792969\n",
      "Epoch  7, Batch 159 - Loss:   209.7266 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 160 - Loss:   356.2293 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 161 - Loss:   472.5264 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 162 - Loss:   337.3398 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 163 - Loss:   231.4148 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 164 - Loss:   357.5354 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 165 - Loss:   192.1061 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 166 - Loss:   245.4746 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 167 - Loss:   303.6240 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 168 - Loss:   450.6695 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 169 - Loss:   414.7062 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 170 - Loss:   306.7645 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 171 - Loss:   313.4669 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 172 - Loss:   297.8980 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 173 - Loss:   335.4151 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 174 - Loss:   345.9068 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 175 - Loss:   232.7016 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 176 - Loss:   248.3312 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 177 - Loss:   449.1735 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 178 - Loss:   401.8324 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 179 - Loss:   355.0384 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 180 - Loss:   370.8468 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 181 - Loss:   398.2133 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 182 - Loss:   457.9922 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 183 - Loss:   316.7420 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 184 - Loss:   254.3667 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 185 - Loss:   310.4161 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 186 - Loss:   273.2448 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 187 - Loss:   255.4225 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 188 - Loss:   351.0036 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 189 - Loss:   364.3588 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 190 - Loss:   227.1903 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 191 - Loss:   266.9443 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 192 - Loss:   294.7923 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 193 - Loss:   268.7312 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 194 - Loss:   414.1705 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 195 - Loss:   277.2587 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 196 - Loss:   526.4995 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 197 - Loss:   475.7650 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 198 - Loss:   336.8560 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 199 - Loss:   342.0738 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 200 - Loss:   334.4813 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 201 - Loss:   511.7788 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 202 - Loss:   337.5529 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 203 - Loss:   406.8842 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 204 - Loss:   280.5973 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 205 - Loss:   453.8083 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 206 - Loss:   457.2069 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 207 - Loss:   406.6044 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 208 - Loss:   462.5537 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 209 - Loss:   445.8762 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 210 - Loss:   455.5098 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 211 - Loss:   387.5378 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 212 - Loss:   303.1994 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 213 - Loss:   276.7455 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 214 - Loss:   523.3248 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 215 - Loss:   260.8174 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 216 - Loss:   243.5134 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 217 - Loss:   340.7663 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 218 - Loss:   242.7408 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 219 - Loss:   490.5480 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 220 - Loss:   200.2513 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 221 - Loss:   229.7550 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 222 - Loss:   347.1529 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 223 - Loss:   396.9764 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 224 - Loss:   216.3319 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 225 - Loss:   386.0169 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 226 - Loss:   427.3801 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 227 - Loss:   397.2177 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 228 - Loss:   336.6678 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 229 - Loss:   347.4513 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 230 - Loss:   162.0817 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 231 - Loss:   274.0023 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 232 - Loss:   395.2341 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 233 - Loss:   266.9313 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 234 - Loss:   429.2931 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 235 - Loss:   184.9001 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 236 - Loss:   288.8999 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 237 - Loss:   295.3967 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 238 - Loss:   340.3133 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 239 - Loss:   308.2518 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 240 - Loss:   411.0889 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 241 - Loss:   414.3055 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 242 - Loss:   274.6025 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 243 - Loss:   315.7603 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 244 - Loss:   249.8290 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 245 - Loss:   430.3354 Validation Accuracy: 0.824219\n",
      "Epoch  7, Batch 246 - Loss:   368.7085 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 247 - Loss:   486.3647 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 248 - Loss:   451.1073 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 249 - Loss:   406.8853 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 250 - Loss:   338.7739 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 251 - Loss:   404.4619 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 252 - Loss:   290.3360 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 253 - Loss:   331.6334 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 254 - Loss:   324.2039 Validation Accuracy: 0.820312\n",
      "Epoch  7, Batch 255 - Loss:   239.6290 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 256 - Loss:   344.9275 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 257 - Loss:   303.3394 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 258 - Loss:   451.4398 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 259 - Loss:   200.8334 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 260 - Loss:   399.0082 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 261 - Loss:   347.5064 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 262 - Loss:   384.9781 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 263 - Loss:   464.3457 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 264 - Loss:   359.9669 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 265 - Loss:   376.0216 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 266 - Loss:   324.4807 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 267 - Loss:   382.6296 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 268 - Loss:   485.5555 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 269 - Loss:   436.0417 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 270 - Loss:   335.5429 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 271 - Loss:   364.5774 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 272 - Loss:   253.7911 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 273 - Loss:   413.2791 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 274 - Loss:   282.7319 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 275 - Loss:   342.7150 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 276 - Loss:   376.2076 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 277 - Loss:   263.7122 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 278 - Loss:   400.4265 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 279 - Loss:   268.9779 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 280 - Loss:   241.6116 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 281 - Loss:   221.8805 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 282 - Loss:   333.3751 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 283 - Loss:   301.5792 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 284 - Loss:   369.9762 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 285 - Loss:   417.4803 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 286 - Loss:   306.3489 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 287 - Loss:   428.2035 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 288 - Loss:   352.3843 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 289 - Loss:   369.4302 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 290 - Loss:   348.5571 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 291 - Loss:   336.5577 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 292 - Loss:   360.8508 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 293 - Loss:   187.9265 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 294 - Loss:   317.3934 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 295 - Loss:   372.6070 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 296 - Loss:   140.4634 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 297 - Loss:   524.3997 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 298 - Loss:   378.8385 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 299 - Loss:   288.9485 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 300 - Loss:   174.9333 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 301 - Loss:   264.4903 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 302 - Loss:   367.5707 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 303 - Loss:   309.5002 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 304 - Loss:   172.4151 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 305 - Loss:   241.8326 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 306 - Loss:   321.6337 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 307 - Loss:   291.4868 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 308 - Loss:   357.4781 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 309 - Loss:   390.4965 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 310 - Loss:   267.5669 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 311 - Loss:   239.0464 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 312 - Loss:   413.7888 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 313 - Loss:   393.2669 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 314 - Loss:   473.5767 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 315 - Loss:   433.3824 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 316 - Loss:   191.8395 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 317 - Loss:   345.4476 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 318 - Loss:   426.6281 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 319 - Loss:   291.5764 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 320 - Loss:   468.6441 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 321 - Loss:   362.2548 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 322 - Loss:   329.1401 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 323 - Loss:   523.4631 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 324 - Loss:   363.9131 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 325 - Loss:   348.2002 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 326 - Loss:   327.3496 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 327 - Loss:   243.4145 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 328 - Loss:   417.0337 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 329 - Loss:   304.6548 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 330 - Loss:   272.9510 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 331 - Loss:   220.9817 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 332 - Loss:   406.5677 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 333 - Loss:   289.9879 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 334 - Loss:   316.8998 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 335 - Loss:   200.1729 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 336 - Loss:   309.2910 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 337 - Loss:   377.0652 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 338 - Loss:   318.4510 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 339 - Loss:   414.9304 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 340 - Loss:   257.8572 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 341 - Loss:   363.0843 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 342 - Loss:   303.4689 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 343 - Loss:   323.6521 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 344 - Loss:   269.0167 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 345 - Loss:   267.2812 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 346 - Loss:   196.2508 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 347 - Loss:   345.6466 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 348 - Loss:   307.8283 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 349 - Loss:   391.6497 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 350 - Loss:   263.6141 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 351 - Loss:   245.4919 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 352 - Loss:   340.3912 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 353 - Loss:   354.1703 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 354 - Loss:   410.2928 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 355 - Loss:   302.0250 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 356 - Loss:   292.8545 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 357 - Loss:   359.4276 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 358 - Loss:   355.7640 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 359 - Loss:   448.5769 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 360 - Loss:   328.8324 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 361 - Loss:   193.7134 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 362 - Loss:   374.1626 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 363 - Loss:   280.1351 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 364 - Loss:   332.0579 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 365 - Loss:   313.8188 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 366 - Loss:   382.6821 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 367 - Loss:   395.9101 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 368 - Loss:   246.8715 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 369 - Loss:   217.8311 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 370 - Loss:   474.1900 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 371 - Loss:   414.6765 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 372 - Loss:   319.2303 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 373 - Loss:   381.5966 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 374 - Loss:   281.1035 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 375 - Loss:   314.7675 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 376 - Loss:   442.3529 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 377 - Loss:   281.8789 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 378 - Loss:   403.4957 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 379 - Loss:   333.2501 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 380 - Loss:   212.3384 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 381 - Loss:   432.3523 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 382 - Loss:   256.5112 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 383 - Loss:   348.6549 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 384 - Loss:   359.1746 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 385 - Loss:   314.5956 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 386 - Loss:   469.2117 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 387 - Loss:   439.6921 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 388 - Loss:   390.8532 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 389 - Loss:   315.8250 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 390 - Loss:   215.6178 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 391 - Loss:   287.8309 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 392 - Loss:   280.6740 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 393 - Loss:   169.3798 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 394 - Loss:   230.8781 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 395 - Loss:   411.7378 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 396 - Loss:   258.2722 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 397 - Loss:   367.4312 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 398 - Loss:   379.9349 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 399 - Loss:   356.4265 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 400 - Loss:   465.1749 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 401 - Loss:   257.1513 Validation Accuracy: 0.816406\n",
      "Epoch  7, Batch 402 - Loss:   333.9923 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 403 - Loss:   264.3785 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 404 - Loss:   189.5020 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 405 - Loss:   371.0132 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 406 - Loss:   306.7493 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 407 - Loss:   489.1230 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 408 - Loss:   183.4380 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 409 - Loss:   232.8742 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 410 - Loss:   341.3142 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 411 - Loss:   248.6854 Validation Accuracy: 0.800781\n",
      "Epoch  7, Batch 412 - Loss:   341.8585 Validation Accuracy: 0.792969\n",
      "Epoch  7, Batch 413 - Loss:   397.7901 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 414 - Loss:   393.0792 Validation Accuracy: 0.796875\n",
      "Epoch  7, Batch 415 - Loss:   422.9171 Validation Accuracy: 0.792969\n",
      "Epoch  7, Batch 416 - Loss:   321.6472 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 417 - Loss:   160.4757 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 418 - Loss:   319.6449 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 419 - Loss:   414.1198 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 420 - Loss:   376.2032 Validation Accuracy: 0.812500\n",
      "Epoch  7, Batch 421 - Loss:   339.1900 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 422 - Loss:   309.5288 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 423 - Loss:   431.5967 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 424 - Loss:   416.6909 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 425 - Loss:   368.7663 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 426 - Loss:   313.8206 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 427 - Loss:   383.1832 Validation Accuracy: 0.808594\n",
      "Epoch  7, Batch 428 - Loss:   406.8065 Validation Accuracy: 0.804688\n",
      "Epoch  7, Batch 429 - Loss:   174.4435 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch   1 - Loss:   332.4397 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch   2 - Loss:   251.5639 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch   3 - Loss:   441.9755 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch   4 - Loss:   320.9035 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch   5 - Loss:   270.5451 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch   6 - Loss:   370.7348 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch   7 - Loss:   455.3607 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch   8 - Loss:   462.8149 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch   9 - Loss:   162.7688 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  10 - Loss:   270.2402 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  11 - Loss:   358.6066 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  12 - Loss:   189.2109 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  13 - Loss:   327.1122 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  14 - Loss:   264.7437 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  15 - Loss:   350.9097 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  16 - Loss:   306.4624 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  17 - Loss:   382.6068 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  18 - Loss:   144.4123 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  19 - Loss:   265.1607 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  20 - Loss:   343.3174 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  21 - Loss:   336.3138 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  22 - Loss:   436.7179 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  23 - Loss:   464.5076 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  24 - Loss:   273.5885 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  25 - Loss:   353.2695 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  26 - Loss:   435.9973 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  27 - Loss:   454.4005 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  28 - Loss:   264.1238 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  29 - Loss:   329.9338 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  30 - Loss:   341.4774 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  31 - Loss:   271.0666 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  32 - Loss:   270.6820 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  33 - Loss:   284.8186 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  34 - Loss:   296.2238 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  35 - Loss:   315.8741 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  36 - Loss:   272.0658 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  37 - Loss:   276.6425 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  38 - Loss:   390.4383 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  39 - Loss:   276.2831 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  40 - Loss:   332.7184 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  41 - Loss:   296.4720 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  42 - Loss:   326.9622 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  43 - Loss:   281.2827 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  44 - Loss:   298.4118 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  45 - Loss:   352.9916 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch  46 - Loss:   550.9486 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  47 - Loss:   336.8068 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch  48 - Loss:   278.6714 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  49 - Loss:   306.8174 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  50 - Loss:   288.2540 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  51 - Loss:   350.6957 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  52 - Loss:   265.9548 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  53 - Loss:   433.8572 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch  54 - Loss:   394.1820 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch  55 - Loss:   370.9031 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch  56 - Loss:   323.2097 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  57 - Loss:   272.1302 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  58 - Loss:   319.9012 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  59 - Loss:   303.5676 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  60 - Loss:   428.0703 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  61 - Loss:   258.3749 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  62 - Loss:   303.2990 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  63 - Loss:   497.7366 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  64 - Loss:   473.7148 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  65 - Loss:   238.3361 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  66 - Loss:   269.6729 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  67 - Loss:   217.0820 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  68 - Loss:   194.6578 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  69 - Loss:   372.8906 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  70 - Loss:   336.5390 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  71 - Loss:   326.7147 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  72 - Loss:   334.3657 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  73 - Loss:   174.7396 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  74 - Loss:   379.7445 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  75 - Loss:   326.3621 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  76 - Loss:   255.5470 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  77 - Loss:   158.3638 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  78 - Loss:   336.4941 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  79 - Loss:   377.4983 Validation Accuracy: 0.800781\n",
      "Epoch  8, Batch  80 - Loss:   470.7520 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  81 - Loss:   450.9963 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch  82 - Loss:   307.9626 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  83 - Loss:   267.7072 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  84 - Loss:   454.0450 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  85 - Loss:   237.0274 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  86 - Loss:   292.7206 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  87 - Loss:   435.9106 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  88 - Loss:   206.0169 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  89 - Loss:   403.9457 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch  90 - Loss:   359.1902 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch  91 - Loss:   256.9610 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  92 - Loss:   353.9376 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch  93 - Loss:   392.6840 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  94 - Loss:   274.2907 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  95 - Loss:   374.0959 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  96 - Loss:   385.2830 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch  97 - Loss:   210.8404 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  98 - Loss:   372.4845 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch  99 - Loss:   342.9581 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 100 - Loss:   475.6630 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 101 - Loss:   397.0042 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 102 - Loss:   259.9694 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 103 - Loss:   344.1369 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 104 - Loss:   281.6718 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 105 - Loss:   298.0444 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 106 - Loss:   273.3975 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 107 - Loss:   164.9483 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 108 - Loss:   390.5172 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 109 - Loss:   276.9297 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 110 - Loss:   287.7223 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 111 - Loss:   258.9112 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 112 - Loss:   272.9648 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 113 - Loss:   212.9540 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 114 - Loss:   313.5036 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 115 - Loss:   498.5904 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 116 - Loss:   264.3354 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 117 - Loss:   225.0530 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 118 - Loss:   315.9283 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 119 - Loss:   372.6207 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 120 - Loss:   412.4487 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 121 - Loss:   369.4896 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 122 - Loss:   318.9614 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 123 - Loss:   323.0928 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 124 - Loss:   367.5749 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 125 - Loss:   263.2334 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 126 - Loss:   208.8110 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 127 - Loss:   390.2178 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 128 - Loss:   253.3402 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 129 - Loss:   296.8616 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 130 - Loss:   258.3802 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 131 - Loss:   307.4555 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 132 - Loss:   205.0909 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 133 - Loss:   346.8649 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 134 - Loss:   336.1779 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 135 - Loss:   455.3726 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 136 - Loss:   294.8777 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 137 - Loss:   357.7264 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 138 - Loss:   297.2022 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 139 - Loss:   354.8308 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 140 - Loss:   333.5698 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 141 - Loss:   324.6289 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 142 - Loss:   436.0702 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 143 - Loss:   185.4763 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 144 - Loss:   334.9666 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 145 - Loss:   277.8463 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 146 - Loss:   239.0665 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 147 - Loss:   428.8916 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 148 - Loss:   370.1642 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 149 - Loss:   365.0007 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 150 - Loss:   297.7498 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 151 - Loss:   319.1224 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 152 - Loss:   318.1448 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 153 - Loss:   313.5946 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 154 - Loss:   340.5453 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 155 - Loss:   372.7869 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 156 - Loss:   389.0904 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 157 - Loss:   329.9543 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 158 - Loss:   335.3643 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 159 - Loss:   222.3066 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 160 - Loss:   203.1518 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 161 - Loss:   201.0046 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 162 - Loss:   291.7961 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 163 - Loss:   364.3364 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 164 - Loss:   228.3403 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 165 - Loss:   431.6863 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 166 - Loss:   293.1880 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 167 - Loss:   511.8740 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch 168 - Loss:   615.6012 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 169 - Loss:   457.7253 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 170 - Loss:   352.3493 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 171 - Loss:   256.7425 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 172 - Loss:   157.7806 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 173 - Loss:   251.0527 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 174 - Loss:   310.8925 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 175 - Loss:   392.3240 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch 176 - Loss:   212.0437 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch 177 - Loss:   331.9843 Validation Accuracy: 0.804688\n",
      "Epoch  8, Batch 178 - Loss:   389.8755 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 179 - Loss:   332.0900 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 180 - Loss:   380.3513 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 181 - Loss:   274.7645 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 182 - Loss:   339.5819 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 183 - Loss:   341.3738 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 184 - Loss:   195.0794 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 185 - Loss:   352.6945 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 186 - Loss:   406.1011 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 187 - Loss:   293.5059 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 188 - Loss:   367.2108 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 189 - Loss:   208.8105 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 190 - Loss:   174.6390 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 191 - Loss:   386.7721 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 192 - Loss:   243.8196 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 193 - Loss:   350.6158 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 194 - Loss:   283.1549 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 195 - Loss:   326.9680 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 196 - Loss:   384.3279 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 197 - Loss:   241.2100 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 198 - Loss:   229.5639 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 199 - Loss:   191.8701 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 200 - Loss:   430.1483 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 201 - Loss:   285.0504 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 202 - Loss:   367.5583 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 203 - Loss:   289.8826 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 204 - Loss:   217.7834 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 205 - Loss:   325.8216 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 206 - Loss:   301.5515 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 207 - Loss:   294.7673 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 208 - Loss:   318.8189 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 209 - Loss:   230.8385 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 210 - Loss:   199.1015 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 211 - Loss:   300.5144 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 212 - Loss:   316.6977 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 213 - Loss:   282.2133 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 214 - Loss:   397.7241 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 215 - Loss:   243.2140 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 216 - Loss:   280.3833 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 217 - Loss:   297.2010 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 218 - Loss:   440.3986 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 219 - Loss:   225.7581 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 220 - Loss:   300.9246 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 221 - Loss:   254.8836 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 222 - Loss:   353.4394 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 223 - Loss:   309.3266 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 224 - Loss:   206.0380 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 225 - Loss:   285.3056 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 226 - Loss:   456.5858 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 227 - Loss:   348.8405 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 228 - Loss:   335.5955 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 229 - Loss:   333.9355 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 230 - Loss:   334.0553 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 231 - Loss:   216.8827 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 232 - Loss:   320.1997 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 233 - Loss:   192.4091 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 234 - Loss:   298.7089 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 235 - Loss:   297.1539 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 236 - Loss:   329.0399 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 237 - Loss:   328.6977 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 238 - Loss:   316.0051 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 239 - Loss:   393.5330 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 240 - Loss:   269.5355 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 241 - Loss:   335.8322 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 242 - Loss:   404.6118 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 243 - Loss:   131.5874 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 244 - Loss:   213.6023 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 245 - Loss:   309.5601 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 246 - Loss:   353.6153 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 247 - Loss:   223.8055 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 248 - Loss:   333.3723 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 249 - Loss:   378.9045 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 250 - Loss:   341.9509 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 251 - Loss:   285.3712 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 252 - Loss:   492.3924 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 253 - Loss:   270.1735 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 254 - Loss:   232.1905 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 255 - Loss:   375.7525 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 256 - Loss:   268.5898 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 257 - Loss:   374.0952 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 258 - Loss:   307.1902 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 259 - Loss:   367.5804 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 260 - Loss:   179.8597 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 261 - Loss:   194.2365 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 262 - Loss:   208.2684 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 263 - Loss:   288.3362 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 264 - Loss:   254.5116 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 265 - Loss:   269.8105 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 266 - Loss:   210.5956 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 267 - Loss:   326.1564 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 268 - Loss:   199.2451 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 269 - Loss:   325.5049 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 270 - Loss:   328.4306 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 271 - Loss:   305.7451 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 272 - Loss:   237.5152 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 273 - Loss:   236.4370 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 274 - Loss:   167.6464 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 275 - Loss:   353.6405 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 276 - Loss:   279.9235 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 277 - Loss:   470.1150 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 278 - Loss:   275.1689 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 279 - Loss:   222.1562 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 280 - Loss:   241.8538 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 281 - Loss:   248.0125 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 282 - Loss:   365.0823 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 283 - Loss:   308.0265 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 284 - Loss:   334.5923 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 285 - Loss:   255.0668 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 286 - Loss:   342.2266 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 287 - Loss:   260.5813 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 288 - Loss:   240.3722 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 289 - Loss:   342.5180 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 290 - Loss:   259.0118 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 291 - Loss:   208.9979 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 292 - Loss:   388.2612 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 293 - Loss:   276.4777 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 294 - Loss:   212.8213 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 295 - Loss:   395.1071 Validation Accuracy: 0.808594\n",
      "Epoch  8, Batch 296 - Loss:   244.5472 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 297 - Loss:   379.5164 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 298 - Loss:   319.2933 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 299 - Loss:   346.6461 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 300 - Loss:   500.2051 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 301 - Loss:   285.2183 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 302 - Loss:   476.6819 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 303 - Loss:   333.5427 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 304 - Loss:   234.8990 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 305 - Loss:   325.3173 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 306 - Loss:   356.1683 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 307 - Loss:   321.5165 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 308 - Loss:   281.4319 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 309 - Loss:   431.8889 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 310 - Loss:   414.3657 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 311 - Loss:   409.2135 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 312 - Loss:   225.8014 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 313 - Loss:   325.7752 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 314 - Loss:   224.9182 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 315 - Loss:   349.9403 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 316 - Loss:   203.7325 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 317 - Loss:   214.9408 Validation Accuracy: 0.812500\n",
      "Epoch  8, Batch 318 - Loss:   225.5779 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 319 - Loss:   312.1464 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 320 - Loss:   207.7838 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 321 - Loss:   298.7225 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 322 - Loss:   273.7736 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 323 - Loss:   222.4325 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 324 - Loss:   306.9625 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 325 - Loss:   302.5766 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 326 - Loss:   322.9619 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 327 - Loss:   216.7497 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 328 - Loss:   347.1831 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 329 - Loss:   345.0066 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 330 - Loss:   293.2298 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 331 - Loss:   337.0339 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 332 - Loss:   318.4560 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 333 - Loss:   302.6866 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 334 - Loss:   200.0725 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 335 - Loss:   276.0656 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 336 - Loss:   175.5262 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 337 - Loss:   382.6535 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 338 - Loss:   355.9194 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 339 - Loss:   343.4580 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 340 - Loss:   371.2701 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 341 - Loss:   352.8970 Validation Accuracy: 0.835938\n",
      "Epoch  8, Batch 342 - Loss:   274.5314 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 343 - Loss:   315.7865 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 344 - Loss:   172.3882 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 345 - Loss:   193.4284 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 346 - Loss:   322.2444 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 347 - Loss:   236.6479 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 348 - Loss:   186.8026 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 349 - Loss:   336.2805 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 350 - Loss:   276.0222 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 351 - Loss:   306.6755 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 352 - Loss:   284.8759 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 353 - Loss:   323.2952 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 354 - Loss:   206.1623 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 355 - Loss:   262.6785 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 356 - Loss:   322.7804 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 357 - Loss:   208.9017 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 358 - Loss:   498.9466 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 359 - Loss:   295.6285 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 360 - Loss:   372.2232 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 361 - Loss:   384.0269 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 362 - Loss:   238.2666 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 363 - Loss:   352.4301 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 364 - Loss:   282.0934 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 365 - Loss:   291.5144 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 366 - Loss:   271.1307 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 367 - Loss:   267.7373 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 368 - Loss:   325.0654 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 369 - Loss:   241.2843 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 370 - Loss:   382.3060 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 371 - Loss:   312.3220 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 372 - Loss:   251.0463 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 373 - Loss:   195.7259 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 374 - Loss:   209.4598 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 375 - Loss:   392.3108 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 376 - Loss:   289.6219 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 377 - Loss:   319.4279 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 378 - Loss:   263.6389 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 379 - Loss:   338.0149 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 380 - Loss:   317.9652 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 381 - Loss:   296.1017 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 382 - Loss:   296.3631 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 383 - Loss:   394.2988 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 384 - Loss:   233.3174 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 385 - Loss:   366.9783 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 386 - Loss:   267.3621 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 387 - Loss:   260.5295 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 388 - Loss:   249.6846 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 389 - Loss:   210.0214 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 390 - Loss:   240.4098 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 391 - Loss:   268.3254 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 392 - Loss:   344.3145 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 393 - Loss:   430.0983 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 394 - Loss:   278.7958 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 395 - Loss:   317.0352 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 396 - Loss:   305.3827 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 397 - Loss:   411.8493 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 398 - Loss:   248.9449 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 399 - Loss:   333.7708 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 400 - Loss:   435.8233 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 401 - Loss:   258.3751 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 402 - Loss:   158.5211 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 403 - Loss:   314.6832 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 404 - Loss:   301.9890 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 405 - Loss:   463.7206 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 406 - Loss:   402.9297 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 407 - Loss:   208.5276 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 408 - Loss:   383.0035 Validation Accuracy: 0.832031\n",
      "Epoch  8, Batch 409 - Loss:   391.9880 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 410 - Loss:   233.3206 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 411 - Loss:   203.9494 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 412 - Loss:   367.8049 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 413 - Loss:   236.3865 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 414 - Loss:   227.4602 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 415 - Loss:   249.2823 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 416 - Loss:   473.6786 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 417 - Loss:   295.5833 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 418 - Loss:   251.5125 Validation Accuracy: 0.816406\n",
      "Epoch  8, Batch 419 - Loss:   248.2823 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 420 - Loss:   206.3258 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 421 - Loss:   290.8542 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 422 - Loss:   188.9373 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 423 - Loss:   373.2607 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 424 - Loss:   319.8756 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 425 - Loss:   196.8114 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 426 - Loss:   284.2173 Validation Accuracy: 0.828125\n",
      "Epoch  8, Batch 427 - Loss:   184.9660 Validation Accuracy: 0.820312\n",
      "Epoch  8, Batch 428 - Loss:   196.9330 Validation Accuracy: 0.824219\n",
      "Epoch  8, Batch 429 - Loss:   373.4230 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch   1 - Loss:   286.0417 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch   2 - Loss:   314.4397 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch   3 - Loss:   315.6957 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch   4 - Loss:   231.0735 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch   5 - Loss:   289.8906 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch   6 - Loss:   348.4327 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch   7 - Loss:   300.5926 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch   8 - Loss:   245.8818 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch   9 - Loss:   193.2940 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  10 - Loss:   180.7649 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  11 - Loss:   383.5703 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  12 - Loss:   196.3486 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  13 - Loss:   320.9276 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  14 - Loss:   242.4225 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  15 - Loss:   235.3938 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  16 - Loss:   319.3584 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  17 - Loss:   253.1096 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  18 - Loss:   262.8194 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  19 - Loss:   347.3435 Validation Accuracy: 0.843750\n",
      "Epoch  9, Batch  20 - Loss:   274.6964 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  21 - Loss:   296.4803 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch  22 - Loss:   414.7311 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch  23 - Loss:   311.1370 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  24 - Loss:   318.2370 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  25 - Loss:   197.1993 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  26 - Loss:   232.0388 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  27 - Loss:   404.3959 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  28 - Loss:   217.9927 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  29 - Loss:   256.8484 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  30 - Loss:   384.9627 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  31 - Loss:   358.1053 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  32 - Loss:   306.9230 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  33 - Loss:   174.6174 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  34 - Loss:   411.6620 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  35 - Loss:   243.6589 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  36 - Loss:   309.1902 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  37 - Loss:   237.8610 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  38 - Loss:   279.7532 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  39 - Loss:   133.4689 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  40 - Loss:   223.7696 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  41 - Loss:   232.2132 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  42 - Loss:   330.7105 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  43 - Loss:   289.0666 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  44 - Loss:   279.6342 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  45 - Loss:   124.2618 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  46 - Loss:   179.4917 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  47 - Loss:   217.9940 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch  48 - Loss:   307.7549 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  49 - Loss:   301.7975 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  50 - Loss:   192.4921 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  51 - Loss:   425.8171 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  52 - Loss:   239.2459 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  53 - Loss:   303.5652 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  54 - Loss:   228.9922 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch  55 - Loss:   339.4800 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  56 - Loss:   267.8093 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch  57 - Loss:   268.2009 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch  58 - Loss:   152.2568 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  59 - Loss:   343.3651 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch  60 - Loss:   307.7905 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  61 - Loss:   196.2241 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  62 - Loss:   379.0937 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  63 - Loss:   314.0234 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  64 - Loss:   278.4249 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  65 - Loss:   318.5603 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  66 - Loss:   264.6010 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  67 - Loss:   373.5547 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  68 - Loss:   268.4167 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  69 - Loss:   170.2679 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  70 - Loss:   359.0924 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  71 - Loss:   168.6329 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  72 - Loss:   224.6264 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  73 - Loss:   142.9907 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  74 - Loss:   357.3281 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  75 - Loss:   231.0970 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  76 - Loss:   299.9431 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  77 - Loss:   419.9813 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  78 - Loss:   235.3096 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  79 - Loss:   316.8383 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  80 - Loss:   349.3218 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  81 - Loss:   262.2108 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch  82 - Loss:   268.1017 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  83 - Loss:   260.7682 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  84 - Loss:   320.6662 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  85 - Loss:   244.9654 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  86 - Loss:   226.5736 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  87 - Loss:   121.1100 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch  88 - Loss:   234.6768 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  89 - Loss:   317.1255 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  90 - Loss:   292.5122 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch  91 - Loss:   291.1547 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  92 - Loss:   206.5681 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  93 - Loss:   211.2126 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  94 - Loss:   207.9012 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  95 - Loss:   362.7021 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  96 - Loss:   370.7823 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  97 - Loss:   323.7372 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  98 - Loss:   356.3305 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch  99 - Loss:   353.1059 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 100 - Loss:   182.8688 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 101 - Loss:   238.9444 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 102 - Loss:   263.6111 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 103 - Loss:   369.2106 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 104 - Loss:   484.7679 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 105 - Loss:   336.8340 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 106 - Loss:   260.6871 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 107 - Loss:   225.9109 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 108 - Loss:   379.5372 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 109 - Loss:   309.0720 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 110 - Loss:   205.5186 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 111 - Loss:   166.7777 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 112 - Loss:   230.9830 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 113 - Loss:   188.1105 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 114 - Loss:   293.8112 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 115 - Loss:   257.1568 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 116 - Loss:   263.7624 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 117 - Loss:   256.7278 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 118 - Loss:   338.9092 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 119 - Loss:   347.9758 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 120 - Loss:   300.9764 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 121 - Loss:   328.5204 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 122 - Loss:   402.7384 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 123 - Loss:   173.9623 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 124 - Loss:   252.8705 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 125 - Loss:   365.7438 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 126 - Loss:   243.5894 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 127 - Loss:   258.3271 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 128 - Loss:   318.5188 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 129 - Loss:   396.7428 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 130 - Loss:   332.9190 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 131 - Loss:   379.3118 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 132 - Loss:   280.2175 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 133 - Loss:   222.6296 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 134 - Loss:   272.2758 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 135 - Loss:   375.6453 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 136 - Loss:   170.9904 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 137 - Loss:   322.4972 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 138 - Loss:   374.2782 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 139 - Loss:   231.9218 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 140 - Loss:   302.6183 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 141 - Loss:   340.7271 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 142 - Loss:   214.9545 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 143 - Loss:   252.3197 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 144 - Loss:   286.6664 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 145 - Loss:   217.4055 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 146 - Loss:   239.8916 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 147 - Loss:   216.8676 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 148 - Loss:   200.4614 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 149 - Loss:   155.8206 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 150 - Loss:   251.4022 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 151 - Loss:   290.2960 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 152 - Loss:   261.7493 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 153 - Loss:   111.5527 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 154 - Loss:   267.0689 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 155 - Loss:   279.8871 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 156 - Loss:   395.2575 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 157 - Loss:   240.4444 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 158 - Loss:   353.8925 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 159 - Loss:   313.5251 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 160 - Loss:   293.4617 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 161 - Loss:   260.9174 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 162 - Loss:   413.0865 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 163 - Loss:   232.9249 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 164 - Loss:   163.3683 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 165 - Loss:   284.1394 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 166 - Loss:   326.3830 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 167 - Loss:   306.2992 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 168 - Loss:   357.0649 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 169 - Loss:   281.5283 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 170 - Loss:   326.3578 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 171 - Loss:   340.6400 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 172 - Loss:   422.9683 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 173 - Loss:   235.8178 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 174 - Loss:   222.5914 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 175 - Loss:   273.8659 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 176 - Loss:   326.0870 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 177 - Loss:   199.6132 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 178 - Loss:   332.1528 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 179 - Loss:   319.5290 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 180 - Loss:   361.5200 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 181 - Loss:   217.3101 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 182 - Loss:   215.4722 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 183 - Loss:   213.9777 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 184 - Loss:   327.4416 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 185 - Loss:   225.8012 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 186 - Loss:   289.2007 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 187 - Loss:   269.9367 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 188 - Loss:   270.6969 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 189 - Loss:   315.9532 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 190 - Loss:   230.5126 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 191 - Loss:   306.9878 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 192 - Loss:   247.2680 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 193 - Loss:   277.0354 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 194 - Loss:   343.3751 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 195 - Loss:   132.5079 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 196 - Loss:   311.4313 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 197 - Loss:   204.8840 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 198 - Loss:   308.1874 Validation Accuracy: 0.839844\n",
      "Epoch  9, Batch 199 - Loss:   160.1780 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 200 - Loss:   308.0193 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 201 - Loss:   181.8460 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 202 - Loss:   252.6764 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 203 - Loss:   182.6076 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 204 - Loss:   305.6607 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 205 - Loss:   303.7467 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 206 - Loss:   267.4143 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 207 - Loss:   279.9771 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 208 - Loss:   324.9377 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 209 - Loss:   222.4131 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 210 - Loss:   309.1443 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 211 - Loss:   419.1742 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 212 - Loss:   224.6691 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 213 - Loss:   277.8786 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 214 - Loss:   242.4154 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 215 - Loss:   335.6032 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 216 - Loss:   228.7781 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 217 - Loss:   355.0217 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 218 - Loss:   196.3967 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 219 - Loss:   427.4361 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 220 - Loss:   250.1270 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 221 - Loss:   383.7413 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 222 - Loss:   212.6289 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 223 - Loss:   233.6455 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 224 - Loss:   348.6049 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 225 - Loss:   194.8305 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 226 - Loss:   354.9762 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 227 - Loss:   232.0201 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 228 - Loss:   258.8264 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 229 - Loss:   177.5969 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 230 - Loss:   251.9472 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 231 - Loss:   336.4791 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 232 - Loss:   303.2943 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 233 - Loss:   247.4008 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 234 - Loss:   271.2990 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 235 - Loss:   255.5242 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 236 - Loss:   238.1908 Validation Accuracy: 0.835938\n",
      "Epoch  9, Batch 237 - Loss:   378.6689 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 238 - Loss:   243.5492 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 239 - Loss:   252.1141 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 240 - Loss:   219.7468 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 241 - Loss:   363.0635 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 242 - Loss:   267.6914 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 243 - Loss:   286.4198 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 244 - Loss:   269.0578 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 245 - Loss:   232.9624 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 246 - Loss:   326.2175 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 247 - Loss:   217.3975 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 248 - Loss:   316.7189 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 249 - Loss:   257.9851 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 250 - Loss:   300.0922 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 251 - Loss:   306.3315 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 252 - Loss:   233.0002 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 253 - Loss:   394.0133 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 254 - Loss:   250.7659 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 255 - Loss:   291.5930 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 256 - Loss:   229.6938 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 257 - Loss:   470.2430 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 258 - Loss:   271.1275 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 259 - Loss:   430.5875 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 260 - Loss:   323.0500 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 261 - Loss:   231.8305 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 262 - Loss:   310.6224 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 263 - Loss:   346.2048 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 264 - Loss:   156.7513 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 265 - Loss:   291.6105 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 266 - Loss:   392.3417 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 267 - Loss:   455.3421 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 268 - Loss:   261.7649 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 269 - Loss:   271.5098 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 270 - Loss:   215.3490 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 271 - Loss:   319.9574 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 272 - Loss:   358.4565 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 273 - Loss:   321.4124 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 274 - Loss:   383.7635 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 275 - Loss:   338.1298 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 276 - Loss:   124.4252 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 277 - Loss:   245.7803 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 278 - Loss:   300.3230 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 279 - Loss:   196.9140 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 280 - Loss:   220.2408 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 281 - Loss:   384.1983 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 282 - Loss:   267.3324 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 283 - Loss:   279.9390 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 284 - Loss:   256.5641 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 285 - Loss:   354.2787 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 286 - Loss:   303.1728 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 287 - Loss:   303.0696 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 288 - Loss:   409.1039 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 289 - Loss:   458.3888 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 290 - Loss:   313.4686 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 291 - Loss:   355.0443 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 292 - Loss:   396.0626 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 293 - Loss:   225.5266 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 294 - Loss:   433.4916 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 295 - Loss:   175.9695 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 296 - Loss:   305.4263 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 297 - Loss:   131.8472 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 298 - Loss:   258.4518 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 299 - Loss:   284.2283 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 300 - Loss:   361.6826 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 301 - Loss:   177.4061 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 302 - Loss:   293.8390 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 303 - Loss:   287.6653 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 304 - Loss:   201.4159 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 305 - Loss:   236.7068 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 306 - Loss:   242.4555 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 307 - Loss:   190.0208 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 308 - Loss:   344.9982 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 309 - Loss:   277.3089 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 310 - Loss:   319.1806 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 311 - Loss:   327.2822 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 312 - Loss:   159.7411 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 313 - Loss:   407.2425 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 314 - Loss:   312.0006 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 315 - Loss:   333.7243 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 316 - Loss:   173.5340 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 317 - Loss:   313.7797 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 318 - Loss:   203.9004 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 319 - Loss:   274.5213 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 320 - Loss:   190.1608 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 321 - Loss:   402.6341 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 322 - Loss:   115.5828 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 323 - Loss:   406.6202 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 324 - Loss:   292.7255 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 325 - Loss:   223.6894 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 326 - Loss:   238.9782 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 327 - Loss:   264.7882 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 328 - Loss:   238.5514 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 329 - Loss:   174.5794 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 330 - Loss:   277.3250 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 331 - Loss:   299.1905 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 332 - Loss:   244.9176 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 333 - Loss:   235.4427 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 334 - Loss:   154.1537 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 335 - Loss:   354.9408 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 336 - Loss:   168.4746 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 337 - Loss:   407.0529 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 338 - Loss:   153.5945 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 339 - Loss:   352.2182 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 340 - Loss:   357.3962 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 341 - Loss:   324.8510 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 342 - Loss:   288.1903 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 343 - Loss:   252.8981 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 344 - Loss:   306.5345 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 345 - Loss:   236.0213 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 346 - Loss:   235.2878 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 347 - Loss:   312.0287 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 348 - Loss:   227.5752 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 349 - Loss:   207.7978 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 350 - Loss:   251.3698 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 351 - Loss:   127.3704 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 352 - Loss:   338.5828 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 353 - Loss:   333.0947 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 354 - Loss:   209.8647 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 355 - Loss:   270.3549 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 356 - Loss:   291.1049 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 357 - Loss:   285.4774 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 358 - Loss:   232.6755 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 359 - Loss:   327.7098 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch 360 - Loss:   264.5690 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch 361 - Loss:   223.8221 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 362 - Loss:   211.6025 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 363 - Loss:   320.9489 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 364 - Loss:   262.0591 Validation Accuracy: 0.808594\n",
      "Epoch  9, Batch 365 - Loss:   310.0747 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 366 - Loss:   422.7219 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 367 - Loss:   249.2765 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 368 - Loss:   189.4321 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 369 - Loss:   368.2189 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 370 - Loss:   219.1645 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 371 - Loss:   200.4297 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 372 - Loss:   318.6229 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 373 - Loss:   338.5430 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 374 - Loss:   159.5797 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 375 - Loss:   373.2021 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 376 - Loss:   382.0446 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 377 - Loss:   294.9433 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 378 - Loss:   277.5005 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 379 - Loss:   339.1697 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 380 - Loss:   266.6609 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 381 - Loss:   259.0432 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 382 - Loss:   261.2503 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 383 - Loss:   241.2549 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 384 - Loss:   305.9627 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 385 - Loss:   260.2804 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 386 - Loss:   149.9294 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 387 - Loss:   303.0142 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 388 - Loss:   274.9312 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 389 - Loss:   354.4833 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 390 - Loss:   286.1815 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 391 - Loss:   185.6486 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 392 - Loss:   165.3291 Validation Accuracy: 0.812500\n",
      "Epoch  9, Batch 393 - Loss:   388.3971 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 394 - Loss:   262.6251 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 395 - Loss:   290.6509 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 396 - Loss:   263.7499 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 397 - Loss:   261.1369 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 398 - Loss:   294.4060 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 399 - Loss:   230.7798 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 400 - Loss:   287.3007 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 401 - Loss:   187.5996 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 402 - Loss:   419.9483 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 403 - Loss:   272.8243 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 404 - Loss:   234.1419 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 405 - Loss:   230.7113 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 406 - Loss:   268.3940 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 407 - Loss:   209.9489 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 408 - Loss:   336.4825 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 409 - Loss:   304.8751 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 410 - Loss:   177.6229 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 411 - Loss:   243.0823 Validation Accuracy: 0.828125\n",
      "Epoch  9, Batch 412 - Loss:   402.6323 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 413 - Loss:   236.7645 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 414 - Loss:   223.9287 Validation Accuracy: 0.816406\n",
      "Epoch  9, Batch 415 - Loss:   249.8279 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 416 - Loss:   283.0915 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 417 - Loss:   343.8273 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 418 - Loss:   167.6364 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 419 - Loss:   188.1727 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 420 - Loss:   275.5173 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 421 - Loss:   281.0009 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 422 - Loss:   213.2428 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 423 - Loss:   173.6731 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 424 - Loss:   262.8859 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 425 - Loss:   224.1606 Validation Accuracy: 0.832031\n",
      "Epoch  9, Batch 426 - Loss:   205.3579 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 427 - Loss:   310.4850 Validation Accuracy: 0.824219\n",
      "Epoch  9, Batch 428 - Loss:   335.8141 Validation Accuracy: 0.820312\n",
      "Epoch  9, Batch 429 - Loss:   236.0872 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch   1 - Loss:   302.1137 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch   2 - Loss:   264.1230 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch   3 - Loss:   299.7252 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch   4 - Loss:   448.6608 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch   5 - Loss:   257.1776 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch   6 - Loss:   248.3380 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch   7 - Loss:   224.7065 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch   8 - Loss:   359.7650 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch   9 - Loss:   289.0380 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  10 - Loss:   178.4385 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  11 - Loss:   226.6374 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  12 - Loss:   181.0768 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  13 - Loss:   183.1143 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  14 - Loss:   168.5599 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  15 - Loss:   258.9677 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  16 - Loss:   167.8811 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  17 - Loss:   405.7738 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  18 - Loss:   275.1701 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  19 - Loss:   333.4863 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  20 - Loss:   200.4894 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  21 - Loss:   353.1358 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  22 - Loss:   308.3427 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  23 - Loss:   240.0340 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  24 - Loss:   292.5195 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  25 - Loss:   114.3464 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  26 - Loss:   271.7438 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  27 - Loss:   137.6625 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  28 - Loss:   247.4362 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  29 - Loss:   284.0101 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  30 - Loss:   380.1023 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  31 - Loss:   305.0808 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  32 - Loss:   335.2784 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  33 - Loss:   272.8868 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  34 - Loss:   245.8348 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  35 - Loss:   263.9651 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  36 - Loss:   216.8794 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  37 - Loss:   335.6701 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  38 - Loss:   205.4738 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  39 - Loss:   372.9154 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  40 - Loss:   149.1479 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  41 - Loss:   223.5831 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  42 - Loss:   411.3690 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  43 - Loss:   200.3735 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  44 - Loss:   272.0538 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  45 - Loss:   327.5196 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  46 - Loss:   300.6547 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  47 - Loss:   347.3174 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  48 - Loss:   300.3528 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  49 - Loss:   310.9074 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  50 - Loss:   126.8324 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  51 - Loss:   142.4809 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  52 - Loss:   294.8427 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  53 - Loss:   165.8015 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  54 - Loss:   296.4131 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  55 - Loss:   160.5296 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  56 - Loss:   246.9663 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  57 - Loss:   292.4016 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  58 - Loss:   256.7159 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  59 - Loss:   161.8795 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  60 - Loss:   353.3147 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  61 - Loss:   394.9769 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  62 - Loss:   429.3697 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  63 - Loss:   366.2435 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  64 - Loss:   255.5724 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  65 - Loss:   189.5163 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  66 - Loss:   285.9744 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  67 - Loss:   188.5436 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  68 - Loss:   357.5391 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  69 - Loss:   254.9628 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  70 - Loss:   222.8784 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  71 - Loss:   276.0748 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  72 - Loss:   299.5643 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  73 - Loss:   265.2681 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  74 - Loss:   330.2181 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  75 - Loss:   202.2880 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  76 - Loss:   220.6616 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  77 - Loss:   167.3525 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  78 - Loss:   258.7490 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  79 - Loss:   266.0651 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  80 - Loss:   230.1064 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  81 - Loss:   228.7104 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  82 - Loss:   276.2170 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch  83 - Loss:   399.2281 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch  84 - Loss:   379.2850 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  85 - Loss:   212.4204 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch  86 - Loss:   134.6440 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  87 - Loss:   129.3428 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  88 - Loss:   382.8087 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  89 - Loss:   203.7701 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  90 - Loss:   271.2334 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  91 - Loss:   259.8706 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch  92 - Loss:   281.8871 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  93 - Loss:   182.8972 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  94 - Loss:   216.7535 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  95 - Loss:   263.5836 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  96 - Loss:   334.9799 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch  97 - Loss:   167.6326 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  98 - Loss:   239.6404 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch  99 - Loss:   217.5356 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 100 - Loss:   447.1906 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 101 - Loss:   177.1167 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 102 - Loss:   233.2262 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 103 - Loss:   191.2568 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 104 - Loss:   202.8060 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 105 - Loss:   230.1100 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 106 - Loss:   297.1945 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 107 - Loss:   443.3529 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 108 - Loss:   203.6211 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 109 - Loss:   380.2978 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 110 - Loss:   330.5196 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 111 - Loss:   222.0059 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 112 - Loss:   233.2018 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 113 - Loss:   190.1386 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 114 - Loss:   206.7705 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 115 - Loss:   332.9383 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 116 - Loss:   187.5272 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 117 - Loss:   332.1031 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 118 - Loss:   180.2966 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 119 - Loss:   221.1564 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 120 - Loss:   439.9407 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 121 - Loss:   431.4721 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 122 - Loss:   243.9911 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 123 - Loss:   272.9967 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 124 - Loss:   365.2071 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 125 - Loss:   319.0209 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 126 - Loss:   238.6569 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 127 - Loss:   328.4084 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 128 - Loss:   274.8607 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 129 - Loss:   279.5946 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 130 - Loss:   232.0762 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 131 - Loss:   244.6560 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 132 - Loss:   248.5544 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 133 - Loss:   163.0557 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 134 - Loss:   274.2264 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 135 - Loss:   276.8964 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 136 - Loss:   222.2875 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 137 - Loss:   247.9255 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 138 - Loss:   298.9066 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 139 - Loss:   313.3275 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 140 - Loss:   154.5002 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 141 - Loss:   243.3899 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 142 - Loss:   177.9923 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 143 - Loss:   294.1482 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 144 - Loss:   289.5034 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 145 - Loss:   321.3208 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 146 - Loss:   275.1723 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 147 - Loss:   258.7535 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 148 - Loss:   220.7104 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 149 - Loss:   250.3751 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 150 - Loss:   319.2398 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 151 - Loss:   215.8617 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 152 - Loss:   251.2644 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 153 - Loss:   308.5919 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 154 - Loss:   184.6528 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 155 - Loss:   189.6229 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 156 - Loss:   200.2304 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 157 - Loss:   403.7615 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 158 - Loss:   301.4853 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 159 - Loss:   318.4157 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 160 - Loss:   292.8742 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 161 - Loss:   211.2837 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 162 - Loss:   337.8647 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 163 - Loss:   212.7208 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 164 - Loss:   283.1930 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 165 - Loss:   248.8791 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 166 - Loss:   265.8058 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 167 - Loss:   218.3235 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 168 - Loss:   247.3975 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 169 - Loss:   394.4146 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 170 - Loss:   296.7256 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 171 - Loss:   287.7087 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 172 - Loss:   224.9631 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 173 - Loss:   299.3897 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 174 - Loss:   279.5919 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 175 - Loss:   201.0786 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 176 - Loss:   215.0042 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 177 - Loss:   405.8007 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 178 - Loss:   221.7842 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 179 - Loss:   289.8994 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 180 - Loss:   241.9214 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 181 - Loss:   234.4129 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 182 - Loss:   237.2583 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 183 - Loss:   281.2687 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 184 - Loss:   435.1358 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 185 - Loss:   258.7740 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 186 - Loss:   277.7315 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 187 - Loss:   297.8284 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 188 - Loss:   321.0468 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 189 - Loss:   237.2966 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 190 - Loss:   281.7527 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 191 - Loss:   176.9662 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 192 - Loss:   328.2928 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 193 - Loss:   291.9437 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 194 - Loss:   177.7391 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 195 - Loss:   205.3595 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 196 - Loss:   423.8350 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 197 - Loss:   424.1841 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 198 - Loss:   349.5022 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 199 - Loss:   247.1510 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 200 - Loss:   257.9812 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 201 - Loss:   157.4091 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 202 - Loss:   184.8893 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 203 - Loss:   185.2583 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 204 - Loss:   256.1451 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 205 - Loss:   404.7372 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 206 - Loss:   187.3423 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 207 - Loss:   300.7083 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 208 - Loss:   144.9357 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 209 - Loss:   201.0642 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 210 - Loss:   178.3233 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 211 - Loss:   215.7148 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 212 - Loss:   316.1776 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 213 - Loss:   255.3545 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 214 - Loss:   216.1882 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 215 - Loss:   163.0912 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 216 - Loss:   248.2417 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 217 - Loss:   221.5278 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 218 - Loss:   272.0275 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 219 - Loss:   383.9428 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 220 - Loss:   250.8914 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 221 - Loss:   207.8800 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 222 - Loss:   294.7881 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 223 - Loss:   202.0686 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 224 - Loss:   187.3264 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 225 - Loss:   208.8096 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 226 - Loss:   303.9114 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 227 - Loss:   283.9448 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 228 - Loss:   280.1042 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 229 - Loss:   222.4537 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 230 - Loss:   244.5818 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 231 - Loss:   213.4987 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 232 - Loss:   166.7247 Validation Accuracy: 0.843750\n",
      "Epoch 10, Batch 233 - Loss:   173.1001 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 234 - Loss:   184.2623 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 235 - Loss:   194.2881 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 236 - Loss:   252.9729 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 237 - Loss:   319.5755 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 238 - Loss:   292.8764 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 239 - Loss:   249.8775 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 240 - Loss:   222.8427 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 241 - Loss:   243.8076 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 242 - Loss:   110.6076 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 243 - Loss:   208.4836 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 244 - Loss:   291.6526 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 245 - Loss:   236.6183 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 246 - Loss:   213.0565 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 247 - Loss:   322.9197 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 248 - Loss:   337.3789 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 249 - Loss:   268.4882 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 250 - Loss:   267.3517 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 251 - Loss:   255.9336 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 252 - Loss:   221.2876 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 253 - Loss:   210.9836 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 254 - Loss:   161.3222 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 255 - Loss:   201.0791 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 256 - Loss:   193.9018 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 257 - Loss:   230.8568 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 258 - Loss:   249.1220 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 259 - Loss:   212.9698 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 260 - Loss:   277.8250 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 261 - Loss:   348.5831 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 262 - Loss:   294.1295 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 263 - Loss:   254.9773 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 264 - Loss:   101.5793 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 265 - Loss:   205.6021 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 266 - Loss:   221.5034 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 267 - Loss:   278.5563 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 268 - Loss:   272.3800 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 269 - Loss:   224.5368 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 270 - Loss:   289.8387 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 271 - Loss:   163.9409 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 272 - Loss:   341.8342 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 273 - Loss:   252.6426 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 274 - Loss:   240.8808 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 275 - Loss:   262.5057 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 276 - Loss:   218.1614 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 277 - Loss:   221.8707 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 278 - Loss:   197.9211 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 279 - Loss:   280.9831 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 280 - Loss:   246.5343 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 281 - Loss:   372.2859 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 282 - Loss:   199.2073 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 283 - Loss:   214.5230 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 284 - Loss:   221.4785 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 285 - Loss:   227.9168 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 286 - Loss:   319.0686 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 287 - Loss:   185.6964 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 288 - Loss:   195.2586 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 289 - Loss:   224.6887 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 290 - Loss:   242.2988 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 291 - Loss:   259.2629 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 292 - Loss:   296.2717 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 293 - Loss:   247.6974 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 294 - Loss:   298.3384 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 295 - Loss:   334.9681 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 296 - Loss:   259.0455 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 297 - Loss:   290.3369 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 298 - Loss:   303.9390 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 299 - Loss:   202.0326 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 300 - Loss:   322.4406 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 301 - Loss:   242.8199 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 302 - Loss:   235.8083 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 303 - Loss:   237.4768 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 304 - Loss:   294.3624 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 305 - Loss:   382.4608 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 306 - Loss:   174.6647 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 307 - Loss:   376.1696 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 308 - Loss:   261.1021 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 309 - Loss:   314.0208 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 310 - Loss:   227.8011 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 311 - Loss:   211.8856 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 312 - Loss:   235.9313 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 313 - Loss:   242.1949 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 314 - Loss:   229.1694 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 315 - Loss:   169.6773 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 316 - Loss:   237.7989 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 317 - Loss:   246.9084 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 318 - Loss:   332.9880 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 319 - Loss:   220.1599 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 320 - Loss:   246.4585 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 321 - Loss:   396.1074 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 322 - Loss:   123.3375 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 323 - Loss:   294.8025 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 324 - Loss:   236.9393 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 325 - Loss:   282.1756 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 326 - Loss:   308.9720 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 327 - Loss:   190.6457 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 328 - Loss:   285.8984 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 329 - Loss:   247.5403 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 330 - Loss:   194.0800 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 331 - Loss:   160.3558 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 332 - Loss:   145.1758 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 333 - Loss:   206.5282 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 334 - Loss:   138.7625 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 335 - Loss:   229.4402 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 336 - Loss:   149.3148 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 337 - Loss:   272.1460 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 338 - Loss:   233.1937 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 339 - Loss:   399.6428 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 340 - Loss:   179.9935 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 341 - Loss:   259.2071 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 342 - Loss:   242.3235 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 343 - Loss:   229.9123 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 344 - Loss:   342.2243 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 345 - Loss:   132.0794 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 346 - Loss:   237.6429 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 347 - Loss:   176.5873 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 348 - Loss:   247.5541 Validation Accuracy: 0.839844\n",
      "Epoch 10, Batch 349 - Loss:   289.9114 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 350 - Loss:   201.5628 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 351 - Loss:   331.8739 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 352 - Loss:   263.3114 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 353 - Loss:   208.6626 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 354 - Loss:   191.8138 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 355 - Loss:   276.4883 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 356 - Loss:   318.5874 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 357 - Loss:   212.5359 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 358 - Loss:   210.1731 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 359 - Loss:   219.5245 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 360 - Loss:   231.6193 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 361 - Loss:   168.9635 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 362 - Loss:   319.2299 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 363 - Loss:   198.0322 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 364 - Loss:   251.6414 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 365 - Loss:   314.8716 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 366 - Loss:   211.6985 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 367 - Loss:   258.4700 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 368 - Loss:   193.8577 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 369 - Loss:   195.6080 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 370 - Loss:   251.7099 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 371 - Loss:   228.3552 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 372 - Loss:   308.5956 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 373 - Loss:   302.8972 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 374 - Loss:   241.5395 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 375 - Loss:   289.3044 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 376 - Loss:   284.6094 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 377 - Loss:   296.6157 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 378 - Loss:   217.5450 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 379 - Loss:   179.2755 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 380 - Loss:   223.2335 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 381 - Loss:   204.3679 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 382 - Loss:   316.6618 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 383 - Loss:   139.6514 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 384 - Loss:   228.8901 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 385 - Loss:   255.6776 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 386 - Loss:   354.0135 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 387 - Loss:   143.2455 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 388 - Loss:   175.7839 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 389 - Loss:   243.2385 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 390 - Loss:   153.4659 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 391 - Loss:   232.3435 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 392 - Loss:   181.1173 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 393 - Loss:   208.2852 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 394 - Loss:   275.8455 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 395 - Loss:   273.6851 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 396 - Loss:   272.5778 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 397 - Loss:   247.7139 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 398 - Loss:   193.9488 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 399 - Loss:   185.6502 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 400 - Loss:   284.6854 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 401 - Loss:   458.9393 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 402 - Loss:   121.9419 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 403 - Loss:   244.5609 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 404 - Loss:   198.0083 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 405 - Loss:   230.4279 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 406 - Loss:   197.3023 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 407 - Loss:   278.1613 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 408 - Loss:   277.5990 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 409 - Loss:   226.0394 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 410 - Loss:   211.3872 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 411 - Loss:   235.1214 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 412 - Loss:   326.3554 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 413 - Loss:   156.0092 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 414 - Loss:   112.6677 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 415 - Loss:   174.3745 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 416 - Loss:   379.2755 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 417 - Loss:   248.3511 Validation Accuracy: 0.820312\n",
      "Epoch 10, Batch 418 - Loss:   264.2603 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 419 - Loss:   124.0770 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 420 - Loss:   320.2895 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 421 - Loss:   208.9251 Validation Accuracy: 0.824219\n",
      "Epoch 10, Batch 422 - Loss:   224.4557 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 423 - Loss:   237.9118 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 424 - Loss:   242.3821 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 425 - Loss:   267.0017 Validation Accuracy: 0.828125\n",
      "Epoch 10, Batch 426 - Loss:   194.4543 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 427 - Loss:   342.9524 Validation Accuracy: 0.832031\n",
      "Epoch 10, Batch 428 - Loss:   315.8970 Validation Accuracy: 0.835938\n",
      "Epoch 10, Batch 429 - Loss:   241.0881 Validation Accuracy: 0.828125\n",
      "Testing Accuracy: 0.7734375\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data - shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
